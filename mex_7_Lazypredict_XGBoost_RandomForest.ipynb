{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Machine Exercise 7\n","## Miguel Luis Martinez, Juan Carlos Roldan, Jeryl Salas | AI 221 WZZQ  Shannon Batch | University of the Philippines Diliman"],"metadata":{"id":"pIwxpu0TIrUt"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DpOWtK_xiQ0R","executionInfo":{"status":"ok","timestamp":1718410651055,"user_tz":-480,"elapsed":10972,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"a71ee7d5-b450-4acf-e706-736074a5e592"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ucimlrepo\n","  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n","Collecting optuna\n","  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting shap\n","  Downloading shap-0.45.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.5/540.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lazypredict\n","  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n","Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.6.2)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n","Collecting slicer==0.0.8 (from shap)\n","  Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.4.2)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.1.0)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.0.3)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","Installing collected packages: slicer, Mako, colorlog, alembic, ucimlrepo, shap, optuna, lazypredict\n","Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 lazypredict-0.2.12 optuna-3.6.1 shap-0.45.1 slicer-0.0.8 ucimlrepo-0.0.7\n"]}],"source":["!pip install ucimlrepo optuna shap lazypredict"]},{"cell_type":"markdown","source":["# 1. Early Stage Diabetes Risk Prediction\n","\n","This dataset contains information on about 500 patients in Bangladesh. Our goal is to predict whether a patient is Positive / Negative for diabetes -- a binary classification problem. The input features"],"metadata":{"id":"JDJEbbWnuyAa"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv\"\n","data = pd.read_csv(url)\n","\n","# Display the first few rows of the dataset\n","data.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"JaS38hu0jNZf","executionInfo":{"status":"ok","timestamp":1718344891481,"user_tz":-480,"elapsed":335,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"721cbe52-63fb-45ff-9612-9eed79a34b56"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n","0   40   Male       No        Yes                 No      Yes         No   \n","1   58   Male       No         No                 No      Yes         No   \n","2   41   Male      Yes         No                 No      Yes        Yes   \n","3   45   Male       No         No                Yes      Yes        Yes   \n","4   60   Male      Yes        Yes                Yes      Yes        Yes   \n","\n","  Genital thrush visual blurring Itching Irritability delayed healing  \\\n","0             No              No     Yes           No             Yes   \n","1             No             Yes      No           No              No   \n","2             No              No     Yes           No             Yes   \n","3            Yes              No     Yes           No             Yes   \n","4             No             Yes     Yes          Yes             Yes   \n","\n","  partial paresis muscle stiffness Alopecia Obesity     class  \n","0              No              Yes      Yes     Yes  Positive  \n","1             Yes               No      Yes      No  Positive  \n","2              No              Yes      Yes      No  Positive  \n","3              No               No       No      No  Positive  \n","4             Yes              Yes      Yes     Yes  Positive  "],"text/html":["\n","  <div id=\"df-98e12aa4-e82b-401e-8661-1b484921d630\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Gender</th>\n","      <th>Polyuria</th>\n","      <th>Polydipsia</th>\n","      <th>sudden weight loss</th>\n","      <th>weakness</th>\n","      <th>Polyphagia</th>\n","      <th>Genital thrush</th>\n","      <th>visual blurring</th>\n","      <th>Itching</th>\n","      <th>Irritability</th>\n","      <th>delayed healing</th>\n","      <th>partial paresis</th>\n","      <th>muscle stiffness</th>\n","      <th>Alopecia</th>\n","      <th>Obesity</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>45</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>60</td>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98e12aa4-e82b-401e-8661-1b484921d630')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-98e12aa4-e82b-401e-8661-1b484921d630 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-98e12aa4-e82b-401e-8661-1b484921d630');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-154fda90-c8ba-41b8-adf7-26c7674721d7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-154fda90-c8ba-41b8-adf7-26c7674721d7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-154fda90-c8ba-41b8-adf7-26c7674721d7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 520,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 16,\n        \"max\": 90,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          79,\n          90,\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polyuria\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polydipsia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sudden weight loss\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weakness\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polyphagia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Genital thrush\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"visual blurring\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Itching\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Irritability\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delayed healing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partial paresis\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"muscle stiffness\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alopecia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Obesity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Negative\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":[" # Part 1: Trip Advisor Travel Reviews\n","This is a dataset consisting of 500+ questionnaers from patients in Sylhet Diabetes Hospital in Sylhet, Bangladesh. The features included in this dataset are age, gender, polyuria, polydipsia, sudden_weight_loss, weakness, polyphagia, genital_thrush, visual_blurring, and itching. Using Optuna, we performed a binary classification by optimizing the best model among MLP Classifier, Random Forest Classifier, XGBoost Classifier, Logistic Regression, Naïve Bayes Classifier, SVM Classifier\n","(SVC), and kNN Classifier\n","\n","\n","## 1.A Data Processing\n","We encoded all categorical features in the dataset using LabelEncoder storing each encoder in a dictionary. We defined X as features and y as target. We then used train_test_split to 80-20 split the dataset for training and testing.\n"],"metadata":{"id":"tEXyjquDteLJ"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Encode categorical features\n","label_encoders = {}\n","for column in data.columns:\n","    if data[column].dtype == 'object':\n","        le = LabelEncoder()\n","        data[column] = le.fit_transform(data[column])\n","        label_encoders[column] = le\n","\n","# Split the data into features and target\n","X = data.drop('class', axis=1)\n","y = data['class']\n","\n","# Split the data into training and testing sets with stratification\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"],"metadata":{"id":"ckp56SxTUD-b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.B Optuna\n","Using Optuna, weidentify the best-performing model and hyperparameters for classification task. We defined an objective function that suggests various classifiers and their corresponding hyperparameters. We then evaluated the model's performance using 10-fold cross-validation and returned the accuracy score. Our objective is to get the highest possible accuracy score out of the hyperparameter and model combination after 100 trials. After 100 trials, the highest training accuracy we were able to get was 0.9784 using the XGBoost model with 914 estimators, a max depth of 3, a learning rate of 0.0698, and a sub sample of 0.5078. This model also had an F1 score of 0.9809.  "],"metadata":{"id":"pPvH6mnctgML"}},{"cell_type":"code","source":["import optuna\n","from sklearn.model_selection import cross_val_score\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","def objective(trial):\n","    classifier_name = trial.suggest_categorical(\"classifier\", [\"MLP\", \"RandomForest\", \"XGBoost\", \"LogisticRegression\", \"NaiveBayes\", \"SVC\", \"kNN\"])\n","\n","    if classifier_name == \"MLP\":\n","        hidden_layer_sizes = trial.suggest_categorical(\"MLP_hidden_layer_sizes\", [(50,50,50), (50,100,50), (100,)])\n","        activation = trial.suggest_categorical(\"MLP_activation\", [\"tanh\", \"relu\"])\n","        solver = trial.suggest_categorical(\"MLP_solver\", [\"sgd\", \"adam\"])\n","        alpha = trial.suggest_loguniform(\"MLP_alpha\", 1e-5, 1e-2)\n","        learning_rate = trial.suggest_categorical(\"MLP_learning_rate\", [\"constant\", \"adaptive\"])\n","        model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, alpha=alpha, learning_rate=learning_rate)\n","\n","    elif classifier_name == \"RandomForest\":\n","        n_estimators = trial.suggest_int(\"RF_n_estimators\", 100, 1000)\n","        max_depth = trial.suggest_int(\"RF_max_depth\", 2, 32, log=True)\n","        min_samples_split = trial.suggest_int(\"RF_min_samples_split\", 2, 14)\n","        min_samples_leaf = trial.suggest_int(\"RF_min_samples_leaf\", 1, 14)\n","        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n","\n","    elif classifier_name == \"XGBoost\":\n","        n_estimators = trial.suggest_int(\"XGB_n_estimators\", 100, 1000)\n","        max_depth = trial.suggest_int(\"XGB_max_depth\", 2, 32, log=True)\n","        learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","        subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, subsample=subsample)\n","\n","    elif classifier_name == \"LogisticRegression\":\n","        C = trial.suggest_loguniform(\"LR_C\", 1e-5, 1e2)\n","        solver = trial.suggest_categorical(\"LR_solver\", [\"lbfgs\", \"liblinear\"])\n","        model = LogisticRegression(C=C, solver=solver)\n","\n","    elif classifier_name == \"NaiveBayes\":\n","        model = GaussianNB()\n","\n","    elif classifier_name == \"SVC\":\n","        C = trial.suggest_loguniform(\"SVC_C\", 1e-5, 1e2)\n","        gamma = trial.suggest_loguniform(\"SVC_gamma\", 1e-5, 1e-1)\n","        model = SVC(C=C, gamma=gamma)\n","\n","    elif classifier_name == \"kNN\":\n","        n_neighbors = trial.suggest_int(\"kNN_n_neighbors\", 1, 20)\n","        weights = trial.suggest_categorical(\"kNN_weights\", [\"uniform\", \"distance\"])\n","        model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n","\n","    score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=10)\n","    accuracy = score.mean()\n","    return accuracy\n","\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=100)\n","\n","best_trial = study.best_trial\n","print(f\"Best trial: {best_trial.value}\")\n","print(\"Best hyperparameters: \", best_trial.params)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejPwPWHEmJPn","executionInfo":{"status":"ok","timestamp":1718347064498,"user_tz":-480,"elapsed":222668,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"b112f2c0-a56e-485a-d66a-f9d1b6792e19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-06-14 06:34:01,658] A new study created in memory with name: no-name-e9060167-0f52-405a-9960-0edd5cf1a2b8\n","<ipython-input-12-8a0918394d7e>:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"LR_C\", 1e-5, 1e2)\n","[I 2024-06-14 06:34:02,463] Trial 0 finished with value: 0.9207317073170733 and parameters: {'classifier': 'LogisticRegression', 'LR_C': 12.53590918983361, 'LR_solver': 'lbfgs'}. Best is trial 0 with value: 0.9207317073170733.\n","<ipython-input-12-8a0918394d7e>:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"LR_C\", 1e-5, 1e2)\n","[I 2024-06-14 06:34:03,060] Trial 1 finished with value: 0.7497677119628338 and parameters: {'classifier': 'LogisticRegression', 'LR_C': 0.00537230143034697, 'LR_solver': 'lbfgs'}. Best is trial 0 with value: 0.9207317073170733.\n","<ipython-input-12-8a0918394d7e>:45: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"SVC_C\", 1e-5, 1e2)\n","<ipython-input-12-8a0918394d7e>:46: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  gamma = trial.suggest_loguniform(\"SVC_gamma\", 1e-5, 1e-1)\n","[I 2024-06-14 06:34:03,622] Trial 2 finished with value: 0.6153310104529617 and parameters: {'classifier': 'SVC', 'SVC_C': 4.092608647352636e-05, 'SVC_gamma': 0.00679211629489761}. Best is trial 0 with value: 0.9207317073170733.\n","[I 2024-06-14 06:34:03,974] Trial 3 finished with value: 0.8609175377468061 and parameters: {'classifier': 'kNN', 'kNN_n_neighbors': 4, 'kNN_weights': 'uniform'}. Best is trial 0 with value: 0.9207317073170733.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:34:07,040] Trial 4 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 914, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.06979949030524546, 'XGB_subsample': 0.5078136617336291}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:34:07,218] Trial 5 finished with value: 0.8747967479674796 and parameters: {'classifier': 'NaiveBayes'}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:34:07,471] Trial 6 finished with value: 0.78130081300813 and parameters: {'classifier': 'kNN', 'kNN_n_neighbors': 11, 'kNN_weights': 'uniform'}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:34:13,408] Trial 7 finished with value: 0.8916376306620208 and parameters: {'classifier': 'RandomForest', 'RF_n_estimators': 315, 'RF_max_depth': 2, 'RF_min_samples_split': 2, 'RF_min_samples_leaf': 3}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:34:13,500] Trial 8 finished with value: 0.8747967479674796 and parameters: {'classifier': 'NaiveBayes'}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:34:13,634] Trial 9 finished with value: 0.8633565621370499 and parameters: {'classifier': 'kNN', 'kNN_n_neighbors': 2, 'kNN_weights': 'uniform'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:34:16,123] Trial 10 finished with value: 0.9735772357723576 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 956, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.08302969608949028, 'XGB_subsample': 0.534248416023269}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:34:19,431] Trial 11 finished with value: 0.9711382113821138 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 989, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.08559733438717228, 'XGB_subsample': 0.5047572998302344}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:34:22,368] Trial 12 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 945, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.07677097342048927, 'XGB_subsample': 0.5021357377433601}. Best is trial 4 with value: 0.9783972125435539.\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 100, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-12-8a0918394d7e>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"MLP_alpha\", 1e-5, 1e-2)\n","[I 2024-06-14 06:34:28,029] Trial 13 finished with value: 0.9398954703832754 and parameters: {'classifier': 'MLP', 'MLP_hidden_layer_sizes': (100,), 'MLP_activation': 'tanh', 'MLP_solver': 'adam', 'MLP_alpha': 0.00039027399198755667, 'MLP_learning_rate': 'constant'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:34:29,847] Trial 14 finished with value: 0.9640534262485481 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 613, 'XGB_max_depth': 5, 'XGB_learning_rate': 0.0377941573303361, 'XGB_subsample': 0.9945278153762567}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:34:32,922] Trial 15 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 682, 'XGB_max_depth': 24, 'XGB_learning_rate': 0.040992689401844806, 'XGB_subsample': 0.6357798734947226}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:34:33,757] Trial 16 finished with value: 0.894192799070848 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 137, 'XGB_max_depth': 2, 'XGB_learning_rate': 0.011092377392587628, 'XGB_subsample': 0.7162074102526838}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:34:49,050] Trial 17 finished with value: 0.8965156794425088 and parameters: {'classifier': 'RandomForest', 'RF_n_estimators': 984, 'RF_max_depth': 20, 'RF_min_samples_split': 14, 'RF_min_samples_leaf': 14}. Best is trial 4 with value: 0.9783972125435539.\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 100, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-12-8a0918394d7e>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"MLP_alpha\", 1e-5, 1e-2)\n","[I 2024-06-14 06:34:57,594] Trial 18 finished with value: 0.8702090592334495 and parameters: {'classifier': 'MLP', 'MLP_hidden_layer_sizes': (50, 100, 50), 'MLP_activation': 'relu', 'MLP_solver': 'sgd', 'MLP_alpha': 1.013187590636849e-05, 'MLP_learning_rate': 'adaptive'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:45: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"SVC_C\", 1e-5, 1e2)\n","<ipython-input-12-8a0918394d7e>:46: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  gamma = trial.suggest_loguniform(\"SVC_gamma\", 1e-5, 1e-1)\n","[I 2024-06-14 06:34:57,767] Trial 19 finished with value: 0.6153310104529617 and parameters: {'classifier': 'SVC', 'SVC_C': 13.951020841321766, 'SVC_gamma': 1.3594269888046301e-05}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:34:59,490] Trial 20 finished with value: 0.9735772357723576 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 807, 'XGB_max_depth': 11, 'XGB_learning_rate': 0.06059145085106796, 'XGB_subsample': 0.5924779044608366}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:01,104] Trial 21 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 689, 'XGB_max_depth': 32, 'XGB_learning_rate': 0.043677261039494875, 'XGB_subsample': 0.6378604311703273}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:03,056] Trial 22 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 815, 'XGB_max_depth': 11, 'XGB_learning_rate': 0.018986209822319956, 'XGB_subsample': 0.5033028838488997}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:04,177] Trial 23 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 422, 'XGB_max_depth': 29, 'XGB_learning_rate': 0.05581418137228305, 'XGB_subsample': 0.6647880955792119}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:06,137] Trial 24 finished with value: 0.9736353077816492 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 837, 'XGB_max_depth': 6, 'XGB_learning_rate': 0.09672844966690473, 'XGB_subsample': 0.7944759485629973}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:07,851] Trial 25 finished with value: 0.9470383275261325 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 489, 'XGB_max_depth': 2, 'XGB_learning_rate': 0.024189551945004162, 'XGB_subsample': 0.5935568107527505}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:10,951] Trial 26 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 889, 'XGB_max_depth': 4, 'XGB_learning_rate': 0.05823280863246134, 'XGB_subsample': 0.8288246929334303}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:35:11,068] Trial 27 finished with value: 0.8747967479674796 and parameters: {'classifier': 'NaiveBayes'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:45: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"SVC_C\", 1e-5, 1e2)\n","<ipython-input-12-8a0918394d7e>:46: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  gamma = trial.suggest_loguniform(\"SVC_gamma\", 1e-5, 1e-1)\n","[I 2024-06-14 06:35:11,242] Trial 28 finished with value: 0.6153310104529617 and parameters: {'classifier': 'SVC', 'SVC_C': 1.1287867139786337e-05, 'SVC_gamma': 0.052746763424395486}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"LR_C\", 1e-5, 1e2)\n","[I 2024-06-14 06:35:11,351] Trial 29 finished with value: 0.6153310104529617 and parameters: {'classifier': 'LogisticRegression', 'LR_C': 1.3404353687935551e-05, 'LR_solver': 'liblinear'}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:35:13,016] Trial 30 finished with value: 0.9085365853658537 and parameters: {'classifier': 'RandomForest', 'RF_n_estimators': 118, 'RF_max_depth': 30, 'RF_min_samples_split': 8, 'RF_min_samples_leaf': 11}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:14,640] Trial 31 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 678, 'XGB_max_depth': 29, 'XGB_learning_rate': 0.04188339975808157, 'XGB_subsample': 0.6281866051676044}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"LR_C\", 1e-5, 1e2)\n","[I 2024-06-14 06:35:14,756] Trial 32 finished with value: 0.9207317073170733 and parameters: {'classifier': 'LogisticRegression', 'LR_C': 45.22404389154599, 'LR_solver': 'liblinear'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:16,373] Trial 33 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 708, 'XGB_max_depth': 19, 'XGB_learning_rate': 0.04710967024436521, 'XGB_subsample': 0.5675222509172545}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:18,095] Trial 34 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 730, 'XGB_max_depth': 17, 'XGB_learning_rate': 0.03304295768806037, 'XGB_subsample': 0.6845654749490747}. Best is trial 4 with value: 0.9783972125435539.\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 100, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-12-8a0918394d7e>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"MLP_alpha\", 1e-5, 1e-2)\n","[I 2024-06-14 06:35:29,475] Trial 35 finished with value: 0.9544715447154474 and parameters: {'classifier': 'MLP', 'MLP_hidden_layer_sizes': (50, 50, 50), 'MLP_activation': 'tanh', 'MLP_solver': 'adam', 'MLP_alpha': 0.0050618550509828955, 'MLP_learning_rate': 'constant'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:30,697] Trial 36 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 523, 'XGB_max_depth': 30, 'XGB_learning_rate': 0.06898705786722376, 'XGB_subsample': 0.6280820314262094}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"LR_C\", 1e-5, 1e2)\n","[I 2024-06-14 06:35:30,803] Trial 37 finished with value: 0.8314169570267131 and parameters: {'classifier': 'LogisticRegression', 'LR_C': 0.011519592777935975, 'LR_solver': 'liblinear'}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:35:30,907] Trial 38 finished with value: 0.9185249709639954 and parameters: {'classifier': 'kNN', 'kNN_n_neighbors': 20, 'kNN_weights': 'distance'}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:35:31,012] Trial 39 finished with value: 0.8747967479674796 and parameters: {'classifier': 'NaiveBayes'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:45: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"SVC_C\", 1e-5, 1e2)\n","<ipython-input-12-8a0918394d7e>:46: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  gamma = trial.suggest_loguniform(\"SVC_gamma\", 1e-5, 1e-1)\n","[I 2024-06-14 06:35:31,193] Trial 40 finished with value: 0.7928571428571428 and parameters: {'classifier': 'SVC', 'SVC_C': 25.07321648603355, 'SVC_gamma': 8.926966017013984e-05}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:33,094] Trial 41 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 818, 'XGB_max_depth': 9, 'XGB_learning_rate': 0.021160178619773255, 'XGB_subsample': 0.5053110823174176}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:35,140] Trial 42 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 906, 'XGB_max_depth': 18, 'XGB_learning_rate': 0.023403419343977, 'XGB_subsample': 0.5425020821164256}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:37,206] Trial 43 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 724, 'XGB_max_depth': 14, 'XGB_learning_rate': 0.015736081946536244, 'XGB_subsample': 0.5092056378677652}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:40,148] Trial 44 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 796, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.029265506228872078, 'XGB_subsample': 0.5604122399663634}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:35:40,307] Trial 45 finished with value: 0.9185249709639954 and parameters: {'classifier': 'kNN', 'kNN_n_neighbors': 18, 'kNN_weights': 'distance'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:42,533] Trial 46 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 621, 'XGB_max_depth': 22, 'XGB_learning_rate': 0.047502182194386865, 'XGB_subsample': 0.7715280393148002}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:35:44,379] Trial 47 finished with value: 0.9759581881533101 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 906, 'XGB_max_depth': 8, 'XGB_learning_rate': 0.07730229108710125, 'XGB_subsample': 0.6284683542362505}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:35:55,322] Trial 48 finished with value: 0.8818815331010453 and parameters: {'classifier': 'RandomForest', 'RF_n_estimators': 788, 'RF_max_depth': 2, 'RF_min_samples_split': 2, 'RF_min_samples_leaf': 1}. Best is trial 4 with value: 0.9783972125435539.\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 100, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-12-8a0918394d7e>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"MLP_alpha\", 1e-5, 1e-2)\n","[I 2024-06-14 06:36:01,162] Trial 49 finished with value: 0.8411730545876888 and parameters: {'classifier': 'MLP', 'MLP_hidden_layer_sizes': (50, 50, 50), 'MLP_activation': 'relu', 'MLP_solver': 'sgd', 'MLP_alpha': 1.4696944385350982e-05, 'MLP_learning_rate': 'adaptive'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:03,508] Trial 50 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 979, 'XGB_max_depth': 12, 'XGB_learning_rate': 0.016582677730461765, 'XGB_subsample': 0.5729557755979167}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:04,478] Trial 51 finished with value: 0.9736353077816492 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 349, 'XGB_max_depth': 31, 'XGB_learning_rate': 0.05315545303926091, 'XGB_subsample': 0.6836891398165131}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:05,407] Trial 52 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 346, 'XGB_max_depth': 23, 'XGB_learning_rate': 0.06516264997999077, 'XGB_subsample': 0.6741489995763017}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:07,384] Trial 53 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 870, 'XGB_max_depth': 24, 'XGB_learning_rate': 0.03837602215154437, 'XGB_subsample': 0.6428529992501691}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:09,249] Trial 54 finished with value: 0.9736353077816492 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 425, 'XGB_max_depth': 32, 'XGB_learning_rate': 0.050515156625218376, 'XGB_subsample': 0.7300363581908903}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:36:09,422] Trial 55 finished with value: 0.8747967479674796 and parameters: {'classifier': 'NaiveBayes'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:11,820] Trial 56 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 613, 'XGB_max_depth': 4, 'XGB_learning_rate': 0.06992116726610564, 'XGB_subsample': 0.5366946775512278}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:13,961] Trial 57 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 773, 'XGB_max_depth': 22, 'XGB_learning_rate': 0.0313358475083279, 'XGB_subsample': 0.5963995608226254}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:45: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"SVC_C\", 1e-5, 1e2)\n","<ipython-input-12-8a0918394d7e>:46: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  gamma = trial.suggest_loguniform(\"SVC_gamma\", 1e-5, 1e-1)\n","[I 2024-06-14 06:36:14,145] Trial 58 finished with value: 0.6153310104529617 and parameters: {'classifier': 'SVC', 'SVC_C': 0.023033865907677337, 'SVC_gamma': 0.0007095422717895174}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:36:14,259] Trial 59 finished with value: 0.9233449477351916 and parameters: {'classifier': 'kNN', 'kNN_n_neighbors': 11, 'kNN_weights': 'distance'}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:36:21,302] Trial 60 finished with value: 0.9301974448315912 and parameters: {'classifier': 'RandomForest', 'RF_n_estimators': 552, 'RF_max_depth': 7, 'RF_min_samples_split': 14, 'RF_min_samples_leaf': 7}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:23,572] Trial 61 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 907, 'XGB_max_depth': 4, 'XGB_learning_rate': 0.057419321016850204, 'XGB_subsample': 0.8498387241912304}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:26,692] Trial 62 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 887, 'XGB_max_depth': 4, 'XGB_learning_rate': 0.05857841976108215, 'XGB_subsample': 0.78990002836227}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:29,085] Trial 63 finished with value: 0.9759581881533101 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 924, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.07802436555437783, 'XGB_subsample': 0.8471695233284424}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:31,210] Trial 64 finished with value: 0.9736353077816492 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 963, 'XGB_max_depth': 27, 'XGB_learning_rate': 0.04437416700390335, 'XGB_subsample': 0.8461716417621773}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"LR_C\", 1e-5, 1e2)\n","[I 2024-06-14 06:36:31,355] Trial 65 finished with value: 0.6153310104529617 and parameters: {'classifier': 'LogisticRegression', 'LR_C': 0.000154205871322436, 'LR_solver': 'lbfgs'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:33,099] Trial 66 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 858, 'XGB_max_depth': 5, 'XGB_learning_rate': 0.08880777812304241, 'XGB_subsample': 0.518689285613971}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:35,014] Trial 67 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 986, 'XGB_max_depth': 6, 'XGB_learning_rate': 0.09953667409530417, 'XGB_subsample': 0.5074863164820533}. Best is trial 4 with value: 0.9783972125435539.\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 100, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-12-8a0918394d7e>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"MLP_alpha\", 1e-5, 1e-2)\n","[I 2024-06-14 06:36:37,434] Trial 68 finished with value: 0.8749128919860627 and parameters: {'classifier': 'MLP', 'MLP_hidden_layer_sizes': (100,), 'MLP_activation': 'relu', 'MLP_solver': 'sgd', 'MLP_alpha': 0.009062408224844838, 'MLP_learning_rate': 'constant'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:39,994] Trial 69 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 842, 'XGB_max_depth': 5, 'XGB_learning_rate': 0.0859740968654322, 'XGB_subsample': 0.532093498877826}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:36:40,151] Trial 70 finished with value: 0.8747967479674796 and parameters: {'classifier': 'NaiveBayes'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:43,519] Trial 71 finished with value: 0.9759581881533101 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 947, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.07330966902590542, 'XGB_subsample': 0.9072138440465939}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:45,134] Trial 72 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 773, 'XGB_max_depth': 4, 'XGB_learning_rate': 0.08880618460942764, 'XGB_subsample': 0.5298147012898088}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:46,553] Trial 73 finished with value: 0.9735772357723576 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 760, 'XGB_max_depth': 2, 'XGB_learning_rate': 0.08685001728839799, 'XGB_subsample': 0.5326407642170768}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:48,003] Trial 74 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 676, 'XGB_max_depth': 5, 'XGB_learning_rate': 0.08614052836306331, 'XGB_subsample': 0.5090474534071994}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:49,389] Trial 75 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 647, 'XGB_max_depth': 5, 'XGB_learning_rate': 0.08892569079781586, 'XGB_subsample': 0.5025386463207149}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:50,837] Trial 76 finished with value: 0.9735772357723576 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 675, 'XGB_max_depth': 5, 'XGB_learning_rate': 0.08957406651609624, 'XGB_subsample': 0.5253538931881091}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:52,208] Trial 77 finished with value: 0.9736353077816492 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 641, 'XGB_max_depth': 6, 'XGB_learning_rate': 0.08259719066266429, 'XGB_subsample': 0.50184808927915}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:45: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"SVC_C\", 1e-5, 1e2)\n","<ipython-input-12-8a0918394d7e>:46: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  gamma = trial.suggest_loguniform(\"SVC_gamma\", 1e-5, 1e-1)\n","[I 2024-06-14 06:36:52,380] Trial 78 finished with value: 0.6153310104529617 and parameters: {'classifier': 'SVC', 'SVC_C': 0.01512931487003674, 'SVC_gamma': 0.09139860416895682}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:53,873] Trial 79 finished with value: 0.9759581881533101 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 674, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.0959476108396246, 'XGB_subsample': 0.5582099588308936}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"LR_C\", 1e-5, 1e2)\n","[I 2024-06-14 06:36:54,234] Trial 80 finished with value: 0.923054587688734 and parameters: {'classifier': 'LogisticRegression', 'LR_C': 0.6443005774671194, 'LR_solver': 'lbfgs'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:56,818] Trial 81 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 757, 'XGB_max_depth': 5, 'XGB_learning_rate': 0.07921773386523935, 'XGB_subsample': 0.5015492185012194}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:36:59,396] Trial 82 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 836, 'XGB_max_depth': 7, 'XGB_learning_rate': 0.09035406805277038, 'XGB_subsample': 0.5471991792016023}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:00,669] Trial 83 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 570, 'XGB_max_depth': 7, 'XGB_learning_rate': 0.09014102946604106, 'XGB_subsample': 0.5488443950408808}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:01,969] Trial 84 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 585, 'XGB_max_depth': 7, 'XGB_learning_rate': 0.09088595368441597, 'XGB_subsample': 0.5482979149376284}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:03,281] Trial 85 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 582, 'XGB_max_depth': 5, 'XGB_learning_rate': 0.09845626022956054, 'XGB_subsample': 0.5837290928597639}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:37:11,693] Trial 86 finished with value: 0.9325783972125435 and parameters: {'classifier': 'RandomForest', 'RF_n_estimators': 549, 'RF_max_depth': 8, 'RF_min_samples_split': 8, 'RF_min_samples_leaf': 6}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:14,772] Trial 87 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 861, 'XGB_max_depth': 7, 'XGB_learning_rate': 0.0656594315216366, 'XGB_subsample': 0.5236203496153874}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:16,189] Trial 88 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 654, 'XGB_max_depth': 4, 'XGB_learning_rate': 0.08248122395379764, 'XGB_subsample': 0.521070765005443}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:37:16,322] Trial 89 finished with value: 0.8056910569105691 and parameters: {'classifier': 'kNN', 'kNN_n_neighbors': 7, 'kNN_weights': 'uniform'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:17,603] Trial 90 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 540, 'XGB_max_depth': 6, 'XGB_learning_rate': 0.0812218472840205, 'XGB_subsample': 0.5505909206022999}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:18,848] Trial 91 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 537, 'XGB_max_depth': 6, 'XGB_learning_rate': 0.08286678396346313, 'XGB_subsample': 0.5241112230755474}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:20,125] Trial 92 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 575, 'XGB_max_depth': 8, 'XGB_learning_rate': 0.07492206488951735, 'XGB_subsample': 0.5499753943933027}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:21,241] Trial 93 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 500, 'XGB_max_depth': 4, 'XGB_learning_rate': 0.0896845572025641, 'XGB_subsample': 0.5261769187453625}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:22,681] Trial 94 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 656, 'XGB_max_depth': 6, 'XGB_learning_rate': 0.08149904209639997, 'XGB_subsample': 0.5489868230636473}. Best is trial 4 with value: 0.9783972125435539.\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 100, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-12-8a0918394d7e>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"MLP_alpha\", 1e-5, 1e-2)\n","[I 2024-06-14 06:37:37,063] Trial 95 finished with value: 0.9640534262485481 and parameters: {'classifier': 'MLP', 'MLP_hidden_layer_sizes': (50, 100, 50), 'MLP_activation': 'tanh', 'MLP_solver': 'adam', 'MLP_alpha': 0.00017123738914587706, 'MLP_learning_rate': 'adaptive'}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:38,603] Trial 96 finished with value: 0.9760162601626016 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 715, 'XGB_max_depth': 8, 'XGB_learning_rate': 0.07242771724172148, 'XGB_subsample': 0.6024720064923422}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:40,222] Trial 97 finished with value: 0.9759581881533101 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 800, 'XGB_max_depth': 4, 'XGB_learning_rate': 0.09199981238324963, 'XGB_subsample': 0.5182175812784097}. Best is trial 4 with value: 0.9783972125435539.\n","<ipython-input-12-8a0918394d7e>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"XGB_learning_rate\", 0.01, 0.1)\n","<ipython-input-12-8a0918394d7e>:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  subsample = trial.suggest_uniform(\"XGB_subsample\", 0.5, 1.0)\n","[I 2024-06-14 06:37:43,319] Trial 98 finished with value: 0.9783972125435539 and parameters: {'classifier': 'XGBoost', 'XGB_n_estimators': 935, 'XGB_max_depth': 7, 'XGB_learning_rate': 0.06492061700113222, 'XGB_subsample': 0.5754178688808915}. Best is trial 4 with value: 0.9783972125435539.\n","[I 2024-06-14 06:37:43,703] Trial 99 finished with value: 0.8747967479674796 and parameters: {'classifier': 'NaiveBayes'}. Best is trial 4 with value: 0.9783972125435539.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial: 0.9783972125435539\n","Best hyperparameters:  {'classifier': 'XGBoost', 'XGB_n_estimators': 914, 'XGB_max_depth': 3, 'XGB_learning_rate': 0.06979949030524546, 'XGB_subsample': 0.5078136617336291}\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","# Train the best model on the full training data\n","best_params = best_trial.params\n","classifier_name = best_params.pop(\"classifier\")\n","if classifier_name == \"MLP\":\n","    model = MLPClassifier(**best_params)\n","elif classifier_name == \"RandomForest\":\n","    model = RandomForestClassifier(**best_params)\n","elif classifier_name == \"XGBoost\":\n","    model = XGBClassifier(**best_params)\n","elif classifier_name == \"LogisticRegression\":\n","    model = LogisticRegression(**best_params)\n","elif classifier_name == \"NaiveBayes\":\n","    model = GaussianNB()\n","elif classifier_name == \"SVC\":\n","    model = SVC(**best_params)\n","elif classifier_name == \"kNN\":\n","    model = KNeighborsClassifier(**best_params)\n","\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","# Calculate accuracy and F1 score\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"F1 Score: {f1}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U75MR6KwmMte","executionInfo":{"status":"ok","timestamp":1718347558854,"user_tz":-480,"elapsed":1044,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"9aff7644-3a8c-4b67-9e86-d6e13ed65312"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9807692307692307\n","F1 Score: 0.9808511271925906\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [06:45:57] WARNING: /workspace/src/learner.cc:742: \n","Parameters: { \"XGB_learning_rate\", \"XGB_max_depth\", \"XGB_n_estimators\", \"XGB_subsample\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]}]},{"cell_type":"markdown","source":["# 1.C Search for higher accuracy score\n","\n","As stated from the paper Islam, M.M.F., et. Al. (2020), the best result was found to be random forest in which they had a weighted average F1 score of 0.98 By doing hyperparameter search using Optuna, we were able to find a better result with a F1 score of 0.9904 and an accuracy of 0.9903 using Random Forest 535 estimators, max depth of 28, minimal sample split of 3, minimal sample leaf of 1"],"metadata":{"id":"7WgRpgU7uE8M"}},{"cell_type":"markdown","source":["### Using Optuna"],"metadata":{"id":"GpRMJ6DSiRFj"}},{"cell_type":"code","source":["def rf_objective(trial):\n","    params = {\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32, log=True),\n","        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 14),\n","        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 14),\n","    }\n","    model = RandomForestClassifier(**params)\n","    score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=10)\n","    accuracy = score.mean()\n","    return accuracy\n","\n","rf_study = optuna.create_study(direction=\"maximize\")\n","rf_study.optimize(rf_objective, n_trials=100)\n","\n","best_rf_trial = rf_study.best_trial\n","print(f\"Best Random Forest trial: {best_rf_trial.value}\")\n","print(\"Best hyperparameters for Random Forest: \", best_rf_trial.params)\n","\n","# Train and evaluate the best Random Forest model\n","best_rf_params = best_rf_trial.params\n","rf_model = RandomForestClassifier(**best_rf_params)\n","rf_model.fit(X_train, y_train)\n","y_rf_pred = rf_model.predict(X_test)\n","\n","rf_accuracy = accuracy_score(y_test, y_rf_pred)\n","rf_f1 = f1_score(y_test, y_rf_pred, average='weighted')\n","print(f\"Random Forest Accuracy: {rf_accuracy}\")\n","print(f\"Random Forest F1 Score: {rf_f1}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_WdvHQ5fv7A","executionInfo":{"status":"ok","timestamp":1718348573914,"user_tz":-480,"elapsed":1000961,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"a00aa889-e136-46d8-e302-11601a457fb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-06-14 06:46:12,730] A new study created in memory with name: no-name-d227114f-cd72-4d58-9fe9-2078711c7a55\n","[I 2024-06-14 06:46:22,644] Trial 0 finished with value: 0.9061556329849012 and parameters: {'n_estimators': 250, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.9061556329849012.\n","[I 2024-06-14 06:46:31,466] Trial 1 finished with value: 0.9062137049941927 and parameters: {'n_estimators': 430, 'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9062137049941927.\n","[I 2024-06-14 06:46:33,515] Trial 2 finished with value: 0.8916957026713126 and parameters: {'n_estimators': 157, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.9062137049941927.\n","[I 2024-06-14 06:46:45,748] Trial 3 finished with value: 0.8941347270615564 and parameters: {'n_estimators': 768, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 1 with value: 0.9062137049941927.\n","[I 2024-06-14 06:46:48,732] Trial 4 finished with value: 0.8892566782810685 and parameters: {'n_estimators': 231, 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 13}. Best is trial 1 with value: 0.9062137049941927.\n","[I 2024-06-14 06:46:55,627] Trial 5 finished with value: 0.9325783972125435 and parameters: {'n_estimators': 337, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.9325783972125435.\n","[I 2024-06-14 06:47:08,292] Trial 6 finished with value: 0.9037746806039489 and parameters: {'n_estimators': 739, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.9325783972125435.\n","[I 2024-06-14 06:47:20,746] Trial 7 finished with value: 0.9325783972125435 and parameters: {'n_estimators': 812, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.9325783972125435.\n","[I 2024-06-14 06:47:32,051] Trial 8 finished with value: 0.8843786295005808 and parameters: {'n_estimators': 694, 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.9325783972125435.\n","[I 2024-06-14 06:47:38,999] Trial 9 finished with value: 0.9301393728222997 and parameters: {'n_estimators': 508, 'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.9325783972125435.\n","[I 2024-06-14 06:47:46,333] Trial 10 finished with value: 0.9180603948896632 and parameters: {'n_estimators': 384, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 5 with value: 0.9325783972125435.\n","[I 2024-06-14 06:48:01,314] Trial 11 finished with value: 0.9325783972125435 and parameters: {'n_estimators': 955, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.9325783972125435.\n","[I 2024-06-14 06:48:17,209] Trial 12 finished with value: 0.922938443670151 and parameters: {'n_estimators': 954, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 5 with value: 0.9325783972125435.\n","[I 2024-06-14 06:48:26,277] Trial 13 finished with value: 0.9446573751451801 and parameters: {'n_estimators': 637, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9446573751451801.\n","[I 2024-06-14 06:48:35,614] Trial 14 finished with value: 0.9422183507549363 and parameters: {'n_estimators': 617, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9446573751451801.\n","[I 2024-06-14 06:48:46,299] Trial 15 finished with value: 0.9373983739837399 and parameters: {'n_estimators': 596, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9446573751451801.\n","[I 2024-06-14 06:48:54,072] Trial 16 finished with value: 0.9302555168408828 and parameters: {'n_estimators': 598, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9446573751451801.\n","[I 2024-06-14 06:49:03,580] Trial 17 finished with value: 0.9543554006968641 and parameters: {'n_estimators': 525, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9543554006968641.\n","[I 2024-06-14 06:49:10,147] Trial 18 finished with value: 0.9253193960511034 and parameters: {'n_estimators': 490, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9543554006968641.\n","[I 2024-06-14 06:49:24,152] Trial 19 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 820, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:49:38,390] Trial 20 finished with value: 0.9735772357723576 and parameters: {'n_estimators': 882, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:49:51,825] Trial 21 finished with value: 0.9735772357723576 and parameters: {'n_estimators': 843, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:50:06,532] Trial 22 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 884, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:50:20,593] Trial 23 finished with value: 0.9494773519163763 and parameters: {'n_estimators': 884, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:50:41,811] Trial 24 finished with value: 0.9373983739837399 and parameters: {'n_estimators': 999, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:51:04,525] Trial 25 finished with value: 0.9108594657375146 and parameters: {'n_estimators': 834, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:51:24,364] Trial 26 finished with value: 0.9735772357723576 and parameters: {'n_estimators': 712, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:51:41,208] Trial 27 finished with value: 0.9519163763066203 and parameters: {'n_estimators': 878, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:51:55,810] Trial 28 finished with value: 0.9663182346109176 and parameters: {'n_estimators': 793, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:52:07,320] Trial 29 finished with value: 0.9591753774680605 and parameters: {'n_estimators': 672, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:52:21,104] Trial 30 finished with value: 0.9205574912891986 and parameters: {'n_estimators': 950, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:52:33,255] Trial 31 finished with value: 0.9614401858304298 and parameters: {'n_estimators': 747, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:52:54,968] Trial 32 finished with value: 0.9662601626016262 and parameters: {'n_estimators': 850, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:53:14,033] Trial 33 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 735, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:53:30,167] Trial 34 finished with value: 0.9493612078977934 and parameters: {'n_estimators': 690, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:53:44,976] Trial 35 finished with value: 0.966376306620209 and parameters: {'n_estimators': 910, 'max_depth': 31, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:53:57,370] Trial 36 finished with value: 0.9037166085946573 and parameters: {'n_estimators': 789, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 11}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:54:10,633] Trial 37 finished with value: 0.9373983739837399 and parameters: {'n_estimators': 832, 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:54:20,325] Trial 38 finished with value: 0.9349593495934959 and parameters: {'n_estimators': 739, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:54:35,219] Trial 39 finished with value: 0.9061556329849012 and parameters: {'n_estimators': 996, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:54:39,235] Trial 40 finished with value: 0.8988966318234611 and parameters: {'n_estimators': 230, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 14}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:54:54,344] Trial 41 finished with value: 0.9663182346109174 and parameters: {'n_estimators': 892, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:55:08,235] Trial 42 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 908, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:55:21,124] Trial 43 finished with value: 0.9663182346109176 and parameters: {'n_estimators': 794, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:55:37,000] Trial 44 finished with value: 0.9422183507549363 and parameters: {'n_estimators': 856, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:55:51,432] Trial 45 finished with value: 0.9302555168408828 and parameters: {'n_estimators': 931, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:55:52,922] Trial 46 finished with value: 0.9349593495934959 and parameters: {'n_estimators': 106, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:56:05,214] Trial 47 finished with value: 0.9373983739837399 and parameters: {'n_estimators': 711, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:56:18,232] Trial 48 finished with value: 0.9013356562137049 and parameters: {'n_estimators': 765, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 12}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:56:31,125] Trial 49 finished with value: 0.9301974448315912 and parameters: {'n_estimators': 811, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:56:41,326] Trial 50 finished with value: 0.959001161440186 and parameters: {'n_estimators': 670, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:56:53,574] Trial 51 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 710, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.9760162601626016.\n","[I 2024-06-14 06:57:03,720] Trial 52 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 560, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:57:13,824] Trial 53 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 573, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:57:26,426] Trial 54 finished with value: 0.9373983739837399 and parameters: {'n_estimators': 545, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:57:37,740] Trial 55 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 466, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:57:43,698] Trial 56 finished with value: 0.9494773519163763 and parameters: {'n_estimators': 452, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:57:51,437] Trial 57 finished with value: 0.9735772357723576 and parameters: {'n_estimators': 390, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:57:57,798] Trial 58 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 469, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:58:02,302] Trial 59 finished with value: 0.9229965156794424 and parameters: {'n_estimators': 309, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:58:10,848] Trial 60 finished with value: 0.9373983739837399 and parameters: {'n_estimators': 477, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:58:19,571] Trial 61 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 569, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:58:28,794] Trial 62 finished with value: 0.9736353077816492 and parameters: {'n_estimators': 577, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 52 with value: 0.9783972125435539.\n","[I 2024-06-14 06:58:40,844] Trial 63 finished with value: 0.9807781649245063 and parameters: {'n_estimators': 535, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 06:58:50,691] Trial 64 finished with value: 0.9688153310104528 and parameters: {'n_estimators': 420, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 06:58:59,347] Trial 65 finished with value: 0.9736353077816492 and parameters: {'n_estimators': 555, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 06:59:14,844] Trial 66 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 515, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 06:59:29,366] Trial 67 finished with value: 0.9519163763066203 and parameters: {'n_estimators': 632, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 06:59:43,650] Trial 68 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 468, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 06:59:51,118] Trial 69 finished with value: 0.9688153310104528 and parameters: {'n_estimators': 431, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 06:59:56,087] Trial 70 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 343, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:02,926] Trial 71 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 331, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:07,207] Trial 72 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 299, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:13,809] Trial 73 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 382, 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:20,760] Trial 74 finished with value: 0.9807781649245063 and parameters: {'n_estimators': 257, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:25,873] Trial 75 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 217, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:32,449] Trial 76 finished with value: 0.9519163763066203 and parameters: {'n_estimators': 288, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:37,276] Trial 77 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 340, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:39,899] Trial 78 finished with value: 0.9807781649245063 and parameters: {'n_estimators': 191, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:42,288] Trial 79 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 167, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:46,620] Trial 80 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 188, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:51,158] Trial 81 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 274, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:00:54,717] Trial 82 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 257, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:05,302] Trial 83 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 601, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:09,735] Trial 84 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 328, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:19,486] Trial 85 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 540, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:24,271] Trial 86 finished with value: 0.9471544715447155 and parameters: {'n_estimators': 355, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:33,961] Trial 87 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 572, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:35,791] Trial 88 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 130, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:42,433] Trial 89 finished with value: 0.9735772357723576 and parameters: {'n_estimators': 507, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:46,520] Trial 90 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 216, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:51,509] Trial 91 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 267, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:55,422] Trial 92 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 276, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:01:58,758] Trial 93 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 241, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:02:02,794] Trial 94 finished with value: 0.9664343786295007 and parameters: {'n_estimators': 192, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:02:12,886] Trial 95 finished with value: 0.9807781649245063 and parameters: {'n_estimators': 628, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:02:23,373] Trial 96 finished with value: 0.9711962833914054 and parameters: {'n_estimators': 604, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:02:33,462] Trial 97 finished with value: 0.9760162601626016 and parameters: {'n_estimators': 642, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:02:42,450] Trial 98 finished with value: 0.9132984901277584 and parameters: {'n_estimators': 575, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 63 with value: 0.9807781649245063.\n","[I 2024-06-14 07:02:52,414] Trial 99 finished with value: 0.9783972125435539 and parameters: {'n_estimators': 532, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 0.9807781649245063.\n"]},{"output_type":"stream","name":"stdout","text":["Best Random Forest trial: 0.9807781649245063\n","Best hyperparameters for Random Forest:  {'n_estimators': 535, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}\n","Random Forest Accuracy: 0.9903846153846154\n","Random Forest F1 Score: 0.9904061137656939\n"]}]},{"cell_type":"markdown","source":["### Using Grid Search"],"metadata":{"id":"EFcn95UXiWF-"}},{"cell_type":"markdown","source":["### Using Bayesian Optimization"],"metadata":{"id":"9g7CY-msixdX"}},{"cell_type":"code","source":["# from hyperopt import fmin, tpe, hp, Trials\n","# from hyperopt.pyll.base import scope\n","# from sklearn.model_selection import cross_val_score\n","\n","# # Define the search space\n","# space = {\n","#     'n_estimators': scope.int(hp.quniform('n_estimators', 100, 1000, 1)),\n","#     'max_depth': scope.int(hp.quniform('max_depth', 2, 50, 1)),\n","#     'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 14, 1)),\n","#     'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 14, 1))\n","# }\n","\n","# # Define the objective function\n","# def objective(params):\n","#     rf = RandomForestClassifier(**params)\n","#     score = cross_val_score(rf, X_train, y_train, cv=10, n_jobs=-1).mean()\n","#     return -score\n","\n","# # Initialize trials object\n","# trials = Trials()\n","\n","# # Run the optimization\n","# best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials, rstate=np.random.RandomState(42))\n","\n","# print(f\"Best parameters: {best}\")\n","\n","# # Convert best parameters to int\n","# best_params = {k: int(v) for k, v in best.items()}\n","\n","# # Train and evaluate the best model\n","# best_rf = RandomForestClassifier(**best_params)\n","# best_rf.fit(X_train, y_train)\n","# y_rf_pred = best_rf.predict(X_test)\n","\n","# rf_accuracy = accuracy_score(y_test, y_rf_pred)\n","# rf_f1 = f1_score(y_test, y_rf_pred, average='weighted')\n","# print(f\"Random Forest Accuracy: {rf_accuracy}\")\n","# print(f\"Random Forest F1 Score: {rf_f1}\")\n"],"metadata":{"id":"xYfLDAIsi2A8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Predicting High School Student Performance\n","\n","The goal here is to use the Student Performance data set from the UCI Repository (https://archive.ics.uci.edu/ml/datasets/Student+Performance) to predict G1, G2, and G3, which are the 1st, 2nd, and 3rd period grades, respectively. This is a regression problem.\n","\n","The dataset contains 30 descriptors on 600+ students from two Portuguese schools. The accompanying paper to this data set was done by Paulo Cortez and Alice Silva, entitled \"Using Data Mining to Predict Secondary School Student Performance\" (http://www3.dsi.uminho.pt/pcortez/student.pdf).\n","\n","Note: We will only be dealing with the math scores for these specific sets of students."],"metadata":{"id":"daZLAPSIu19Q"}},{"cell_type":"code","source":["import zipfile\n","import pandas as pd\n","import requests\n","from io import BytesIO\n","\n","# Download the zip file\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\"\n","response = requests.get(url)\n","zip_file = zipfile.ZipFile(BytesIO(response.content))\n","\n","# Extract the contents of the zip file\n","zip_file.extractall()\n","\n","# Load the specific CSV file into a DataFrame\n","data = pd.read_csv(\"student-mat.csv\", sep=\";\")\n","\n","# Display the first few rows of the DataFrame\n","print(data.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZHyeww0j9kj","executionInfo":{"status":"ok","timestamp":1718455041203,"user_tz":-480,"elapsed":1104,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"84d44544-e54a-4e52-bc46-a61d0d3a1ac2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n","0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n","1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n","2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n","3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n","4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n","\n","  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n","0      4        3      4     1     1      3        6   5   6   6  \n","1      5        3      3     1     1      3        4   5   5   6  \n","2      4        3      2     2     3      3       10   7   8  10  \n","3      3        2      2     1     1      5        2  15  14  15  \n","4      4        3      2     1     2      5        4   6  10  10  \n","\n","[5 rows x 33 columns]\n"]}]},{"cell_type":"markdown","source":["## 2A: Data Preprocessing\n","\n","In this first part, we will first be making the necessary encoding for categorical inputs. We will be splitting the data into 80% Training and 20% Test sets."],"metadata":{"id":"r3j4vroJvN66"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Encode categorical variables\n","label_encoders = {}\n","for column in data.select_dtypes(include=['object']).columns:\n","    le = LabelEncoder()\n","    data[column] = le.fit_transform(data[column])\n","    label_encoders[column] = le\n","\n","# Split the data into training and testing sets\n","X = data.drop(['G1', 'G2', 'G3'], axis=1)\n","y = data[['G1', 'G2', 'G3']]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"metadata":{"id":"XRzJqEmFkmg5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2B: Auto-ML Application\n","\n","In this second phase, we will be running any Auto-ML procedure (either LazyPredict, Optuna, TPOT) to predict the G3 score using the 30 descriptors and the G1 and G2 scores as input features (32 features in all). We will be using Optuna specifically for this exercise across 3 different ML models: RandomForestRegressor, GradientBoostingRegressor, and XGBRegressor.\n"],"metadata":{"id":"3-GfiuRWvw1H"}},{"cell_type":"code","source":["import optuna\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from xgboost import XGBRegressor\n","from sklearn.metrics import r2_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Load the data\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\"\n","data = pd.read_csv(\"student-mat.csv\", sep=\";\")\n","\n","# Encode categorical variables\n","label_encoders = {}\n","for column in data.select_dtypes(include=['object']).columns:\n","    le = LabelEncoder()\n","    data[column] = le.fit_transform(data[column])\n","    label_encoders[column] = le\n","\n","# Define features and target\n","X = data.drop(['G3'], axis=1)\n","y = data['G3']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","def objective(trial):\n","    # Define model selection\n","    model_name = trial.suggest_categorical('model', ['RandomForest', 'GradientBoosting', 'XGBoost'])\n","\n","    if model_name == 'RandomForest':\n","        n_estimators = trial.suggest_int('n_estimators', 10, 200)\n","        max_depth = trial.suggest_int('max_depth', 2, 32)\n","        min_samples_split = trial.suggest_int('min_samples_split', 2, 14)\n","        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 14)\n","        model = RandomForestRegressor(\n","            n_estimators=n_estimators,\n","            max_depth=max_depth,\n","            min_samples_split=min_samples_split,\n","            min_samples_leaf=min_samples_leaf,\n","            random_state=42\n","        )\n","\n","    elif model_name == 'GradientBoosting':\n","        n_estimators = trial.suggest_int('n_estimators', 10, 200)\n","        max_depth = trial.suggest_int('max_depth', 2, 32)\n","        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n","        model = GradientBoostingRegressor(\n","            n_estimators=n_estimators,\n","            max_depth=max_depth,\n","            learning_rate=learning_rate,\n","            random_state=42\n","        )\n","\n","    elif model_name == 'XGBoost':\n","        n_estimators = trial.suggest_int('n_estimators', 10, 200)\n","        max_depth = trial.suggest_int('max_depth', 2, 32)\n","        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n","        model = XGBRegressor(\n","            n_estimators=n_estimators,\n","            max_depth=max_depth,\n","            learning_rate=learning_rate,\n","            random_state=42\n","        )\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate the R2 score\n","    score = r2_score(y_test, y_pred)\n","\n","    return score\n","\n","# Create a study object and optimize the objective function\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=500)\n","\n","# Print the best hyperparameters and model\n","print(f\"Best model: {study.best_trial.params['model']}\")\n","print(f\"Best hyperparameters: {study.best_params}\")\n","print(f\"Best R2 score: {study.best_value}\")\n","\n","# Train the final model with the best hyperparameters\n","best_model_name = study.best_trial.params['model']\n","best_params = study.best_params\n","\n","if best_model_name == 'RandomForest':\n","    best_model = RandomForestRegressor(\n","        n_estimators=best_params['n_estimators'],\n","        max_depth=best_params['max_depth'],\n","        min_samples_split=best_params['min_samples_split'],\n","        min_samples_leaf=best_params['min_samples_leaf'],\n","        random_state=42\n","    )\n","\n","elif best_model_name == 'GradientBoosting':\n","    best_model = GradientBoostingRegressor(\n","        n_estimators=best_params['n_estimators'],\n","        max_depth=best_params['max_depth'],\n","        learning_rate=best_params['learning_rate'],\n","        random_state=42\n","    )\n","\n","elif best_model_name == 'XGBoost':\n","    best_model = XGBRegressor(\n","        n_estimators=best_params['n_estimators'],\n","        max_depth=best_params['max_depth'],\n","        learning_rate=best_params['learning_rate'],\n","        random_state=42\n","    )\n","\n","best_model.fit(X_train, y_train)\n","y_pred = best_model.predict(X_test)\n","final_score = r2_score(y_test, y_pred)\n","print(f\"Final R2 score: {final_score}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjF3krL-ksbz","executionInfo":{"status":"ok","timestamp":1718457244386,"user_tz":-480,"elapsed":158848,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"56a7d53f-1def-4d8a-8ae5-b3579738ce50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-06-15 13:11:25,624] A new study created in memory with name: no-name-d30904d4-6477-48c9-9246-dfc251522c34\n","[I 2024-06-15 13:11:26,218] Trial 0 finished with value: 0.7400195684951455 and parameters: {'model': 'GradientBoosting', 'n_estimators': 135, 'max_depth': 25, 'learning_rate': 0.19644581112749532}. Best is trial 0 with value: 0.7400195684951455.\n","[I 2024-06-15 13:11:28,024] Trial 1 finished with value: 0.7830533805162335 and parameters: {'model': 'XGBoost', 'n_estimators': 47, 'max_depth': 30, 'learning_rate': 0.26743679332786713}. Best is trial 1 with value: 0.7830533805162335.\n","[I 2024-06-15 13:11:29,074] Trial 2 finished with value: 0.783342792461248 and parameters: {'model': 'XGBoost', 'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.06825718650480755}. Best is trial 2 with value: 0.783342792461248.\n","[I 2024-06-15 13:11:29,458] Trial 3 finished with value: 0.7511769243400358 and parameters: {'model': 'XGBoost', 'n_estimators': 44, 'max_depth': 23, 'learning_rate': 0.12496529173091153}. Best is trial 2 with value: 0.783342792461248.\n","[I 2024-06-15 13:11:29,560] Trial 4 finished with value: 0.61386070076607 and parameters: {'model': 'GradientBoosting', 'n_estimators': 33, 'max_depth': 27, 'learning_rate': 0.023242725636094648}. Best is trial 2 with value: 0.783342792461248.\n","[I 2024-06-15 13:11:30,137] Trial 5 finished with value: 0.8599323024050874 and parameters: {'model': 'RandomForest', 'n_estimators': 152, 'max_depth': 16, 'min_samples_split': 11, 'min_samples_leaf': 14}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:30,821] Trial 6 finished with value: 0.8425938303820523 and parameters: {'model': 'RandomForest', 'n_estimators': 179, 'max_depth': 31, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:31,706] Trial 7 finished with value: 0.851542706283068 and parameters: {'model': 'RandomForest', 'n_estimators': 188, 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 11}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:32,101] Trial 8 finished with value: 0.8588063035165671 and parameters: {'model': 'RandomForest', 'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:34,200] Trial 9 finished with value: 0.7560616518956759 and parameters: {'model': 'XGBoost', 'n_estimators': 189, 'max_depth': 23, 'learning_rate': 0.12643937892991294}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:34,887] Trial 10 finished with value: 0.820351480930547 and parameters: {'model': 'RandomForest', 'n_estimators': 141, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:35,278] Trial 11 finished with value: 0.859451101171892 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:35,760] Trial 12 finished with value: 0.859451101171892 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 14}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:36,128] Trial 13 finished with value: 0.8531584590610439 and parameters: {'model': 'RandomForest', 'n_estimators': 76, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.8599323024050874.\n","[I 2024-06-15 13:11:37,113] Trial 14 finished with value: 0.8601567596421466 and parameters: {'model': 'RandomForest', 'n_estimators': 153, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 14}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:37,624] Trial 15 finished with value: 0.8190445042103862 and parameters: {'model': 'RandomForest', 'n_estimators': 157, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:37,952] Trial 16 finished with value: 0.8255439699925212 and parameters: {'model': 'GradientBoosting', 'n_estimators': 160, 'max_depth': 7, 'learning_rate': 0.2804093212972447}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:38,209] Trial 17 finished with value: 0.8487569469607721 and parameters: {'model': 'RandomForest', 'n_estimators': 120, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 11}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:38,702] Trial 18 finished with value: 0.845129666539533 and parameters: {'model': 'RandomForest', 'n_estimators': 163, 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 12}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:38,786] Trial 19 finished with value: 0.7441497369052078 and parameters: {'model': 'GradientBoosting', 'n_estimators': 10, 'max_depth': 17, 'learning_rate': 0.20561695661298607}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:39,272] Trial 20 finished with value: 0.8396724916730782 and parameters: {'model': 'RandomForest', 'n_estimators': 141, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:39,549] Trial 21 finished with value: 0.8564974681641948 and parameters: {'model': 'RandomForest', 'n_estimators': 77, 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 13}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:39,888] Trial 22 finished with value: 0.8598085228184051 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:40,271] Trial 23 finished with value: 0.8476879041113523 and parameters: {'model': 'RandomForest', 'n_estimators': 102, 'max_depth': 20, 'min_samples_split': 12, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:40,728] Trial 24 finished with value: 0.8539806292915324 and parameters: {'model': 'RandomForest', 'n_estimators': 125, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 13}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:41,405] Trial 25 finished with value: 0.8538103994655304 and parameters: {'model': 'RandomForest', 'n_estimators': 199, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 12}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:42,052] Trial 26 finished with value: 0.8360654708258295 and parameters: {'model': 'RandomForest', 'n_estimators': 166, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:42,262] Trial 27 finished with value: 0.8556145592665232 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 12}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:42,619] Trial 28 finished with value: 0.7482478236860257 and parameters: {'model': 'XGBoost', 'n_estimators': 149, 'max_depth': 22, 'learning_rate': 0.027366056801399447}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:42,868] Trial 29 finished with value: 0.7379050731128076 and parameters: {'model': 'GradientBoosting', 'n_estimators': 130, 'max_depth': 26, 'learning_rate': 0.2219376232880685}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:43,144] Trial 30 finished with value: 0.8284084498034555 and parameters: {'model': 'GradientBoosting', 'n_estimators': 112, 'max_depth': 7, 'learning_rate': 0.09727202484397075}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:43,307] Trial 31 finished with value: 0.859581655601305 and parameters: {'model': 'RandomForest', 'n_estimators': 64, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:43,458] Trial 32 finished with value: 0.858223245175767 and parameters: {'model': 'RandomForest', 'n_estimators': 60, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:43,626] Trial 33 finished with value: 0.8571909170143095 and parameters: {'model': 'RandomForest', 'n_estimators': 64, 'max_depth': 17, 'min_samples_split': 11, 'min_samples_leaf': 13}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:43,806] Trial 34 finished with value: 0.7679965592050471 and parameters: {'model': 'XGBoost', 'n_estimators': 94, 'max_depth': 19, 'learning_rate': 0.17083155077263718}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:43,900] Trial 35 finished with value: 0.8468477658525697 and parameters: {'model': 'RandomForest', 'n_estimators': 31, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 14}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:44,054] Trial 36 finished with value: 0.8535149847440727 and parameters: {'model': 'RandomForest', 'n_estimators': 57, 'max_depth': 28, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:44,205] Trial 37 finished with value: 0.7674720758808968 and parameters: {'model': 'XGBoost', 'n_estimators': 173, 'max_depth': 5, 'learning_rate': 0.24688567512625972}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:44,465] Trial 38 finished with value: 0.8529775445556815 and parameters: {'model': 'RandomForest', 'n_estimators': 112, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 13}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:44,591] Trial 39 finished with value: 0.8508201786507978 and parameters: {'model': 'RandomForest', 'n_estimators': 42, 'max_depth': 22, 'min_samples_split': 11, 'min_samples_leaf': 12}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:44,963] Trial 40 finished with value: 0.7285091921137665 and parameters: {'model': 'GradientBoosting', 'n_estimators': 136, 'max_depth': 12, 'learning_rate': 0.07054260166352495}. Best is trial 14 with value: 0.8601567596421466.\n","[I 2024-06-15 13:11:45,161] Trial 41 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:45,370] Trial 42 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:45,564] Trial 43 finished with value: 0.8583179770838265 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 18, 'min_samples_split': 13, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:45,810] Trial 44 finished with value: 0.8552979521837816 and parameters: {'model': 'RandomForest', 'n_estimators': 107, 'max_depth': 13, 'min_samples_split': 12, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:46,006] Trial 45 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:46,179] Trial 46 finished with value: 0.7645092456078876 and parameters: {'model': 'XGBoost', 'n_estimators': 71, 'max_depth': 21, 'learning_rate': 0.16046301705184243}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:46,379] Trial 47 finished with value: 0.856957036439807 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 12}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:46,721] Trial 48 finished with value: 0.850115102843424 and parameters: {'model': 'RandomForest', 'n_estimators': 148, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:47,097] Trial 49 finished with value: 0.8602022215381664 and parameters: {'model': 'RandomForest', 'n_estimators': 185, 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:47,468] Trial 50 finished with value: 0.8569506382859791 and parameters: {'model': 'RandomForest', 'n_estimators': 186, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:47,835] Trial 51 finished with value: 0.8610054435286688 and parameters: {'model': 'RandomForest', 'n_estimators': 178, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:48,242] Trial 52 finished with value: 0.8590317152800682 and parameters: {'model': 'RandomForest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:48,588] Trial 53 finished with value: 0.8606277756727952 and parameters: {'model': 'RandomForest', 'n_estimators': 177, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:49,015] Trial 54 finished with value: 0.8392561568196777 and parameters: {'model': 'RandomForest', 'n_estimators': 177, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 2}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:49,334] Trial 55 finished with value: 0.859619007180277 and parameters: {'model': 'RandomForest', 'n_estimators': 171, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:49,746] Trial 56 finished with value: 0.851426061008872 and parameters: {'model': 'RandomForest', 'n_estimators': 195, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 11}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:50,068] Trial 57 finished with value: 0.8568209634491588 and parameters: {'model': 'RandomForest', 'n_estimators': 157, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:50,308] Trial 58 finished with value: 0.7313508245177256 and parameters: {'model': 'GradientBoosting', 'n_estimators': 193, 'max_depth': 12, 'learning_rate': 0.29657177604201945}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:50,672] Trial 59 finished with value: 0.8600490630103825 and parameters: {'model': 'RandomForest', 'n_estimators': 186, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:51,065] Trial 60 finished with value: 0.8552562482356487 and parameters: {'model': 'RandomForest', 'n_estimators': 180, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 12}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:51,442] Trial 61 finished with value: 0.8604013066131124 and parameters: {'model': 'RandomForest', 'n_estimators': 184, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:51,791] Trial 62 finished with value: 0.860140297124358 and parameters: {'model': 'RandomForest', 'n_estimators': 167, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:52,267] Trial 63 finished with value: 0.8574221631998936 and parameters: {'model': 'RandomForest', 'n_estimators': 183, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:52,834] Trial 64 finished with value: 0.8606603240163163 and parameters: {'model': 'RandomForest', 'n_estimators': 177, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:53,365] Trial 65 finished with value: 0.8449730433919692 and parameters: {'model': 'RandomForest', 'n_estimators': 192, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:54,184] Trial 66 finished with value: 0.819468305367326 and parameters: {'model': 'XGBoost', 'n_estimators': 174, 'max_depth': 4, 'learning_rate': 0.24205151526736285}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:54,731] Trial 67 finished with value: 0.8604217888182166 and parameters: {'model': 'RandomForest', 'n_estimators': 162, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:55,312] Trial 68 finished with value: 0.8564474600266441 and parameters: {'model': 'RandomForest', 'n_estimators': 167, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:55,633] Trial 69 finished with value: 0.8517254879028131 and parameters: {'model': 'RandomForest', 'n_estimators': 162, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 12}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:56,011] Trial 70 finished with value: 0.8379840404475111 and parameters: {'model': 'RandomForest', 'n_estimators': 179, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:56,404] Trial 71 finished with value: 0.8591761570431896 and parameters: {'model': 'RandomForest', 'n_estimators': 189, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:56,741] Trial 72 finished with value: 0.8611253452878176 and parameters: {'model': 'RandomForest', 'n_estimators': 170, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:57,080] Trial 73 finished with value: 0.8601200708059078 and parameters: {'model': 'RandomForest', 'n_estimators': 156, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:57,474] Trial 74 finished with value: 0.8250199595684513 and parameters: {'model': 'RandomForest', 'n_estimators': 174, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:57,647] Trial 75 finished with value: 0.8597168242064438 and parameters: {'model': 'RandomForest', 'n_estimators': 72, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:57,909] Trial 76 finished with value: 0.8076767891770978 and parameters: {'model': 'GradientBoosting', 'n_estimators': 148, 'max_depth': 5, 'learning_rate': 0.058412288908713486}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:58,258] Trial 77 finished with value: 0.8544647147538998 and parameters: {'model': 'RandomForest', 'n_estimators': 168, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:58,611] Trial 78 finished with value: 0.8610860475467751 and parameters: {'model': 'RandomForest', 'n_estimators': 181, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:58,827] Trial 79 finished with value: 0.7642444154420787 and parameters: {'model': 'XGBoost', 'n_estimators': 100, 'max_depth': 32, 'learning_rate': 0.12724600526125307}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:59,191] Trial 80 finished with value: 0.8538724811627634 and parameters: {'model': 'RandomForest', 'n_estimators': 162, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 12}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:59,553] Trial 81 finished with value: 0.8610350190021548 and parameters: {'model': 'RandomForest', 'n_estimators': 179, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:11:59,918] Trial 82 finished with value: 0.8576281569604913 and parameters: {'model': 'RandomForest', 'n_estimators': 179, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:00,241] Trial 83 finished with value: 0.8466883930436502 and parameters: {'model': 'RandomForest', 'n_estimators': 171, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:00,525] Trial 84 finished with value: 0.8596238225133261 and parameters: {'model': 'RandomForest', 'n_estimators': 142, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:00,889] Trial 85 finished with value: 0.857360079870126 and parameters: {'model': 'RandomForest', 'n_estimators': 176, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:01,296] Trial 86 finished with value: 0.859502752462672 and parameters: {'model': 'RandomForest', 'n_estimators': 197, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:01,677] Trial 87 finished with value: 0.8555743544674513 and parameters: {'model': 'RandomForest', 'n_estimators': 191, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:02,134] Trial 88 finished with value: 0.8610860475467751 and parameters: {'model': 'RandomForest', 'n_estimators': 181, 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:02,298] Trial 89 finished with value: 0.8035520006189265 and parameters: {'model': 'GradientBoosting', 'n_estimators': 81, 'max_depth': 4, 'learning_rate': 0.1892427155252175}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:02,521] Trial 90 finished with value: 0.8483820626297734 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 9}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:02,893] Trial 91 finished with value: 0.86082101410008 and parameters: {'model': 'RandomForest', 'n_estimators': 182, 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:03,323] Trial 92 finished with value: 0.86082101410008 and parameters: {'model': 'RandomForest', 'n_estimators': 182, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:03,702] Trial 93 finished with value: 0.8574221631998936 and parameters: {'model': 'RandomForest', 'n_estimators': 183, 'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:04,074] Trial 94 finished with value: 0.86081319185587 and parameters: {'model': 'RandomForest', 'n_estimators': 182, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:04,480] Trial 95 finished with value: 0.8591685517155316 and parameters: {'model': 'RandomForest', 'n_estimators': 189, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:04,712] Trial 96 finished with value: 0.8547536404849478 and parameters: {'model': 'RandomForest', 'n_estimators': 105, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:05,121] Trial 97 finished with value: 0.8594596927936459 and parameters: {'model': 'RandomForest', 'n_estimators': 196, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:05,360] Trial 98 finished with value: 0.7860904711081655 and parameters: {'model': 'XGBoost', 'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.10762773362675335}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:05,975] Trial 99 finished with value: 0.8575596113513178 and parameters: {'model': 'RandomForest', 'n_estimators': 182, 'max_depth': 15, 'min_samples_split': 12, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:06,636] Trial 100 finished with value: 0.8590317152800682 and parameters: {'model': 'RandomForest', 'n_estimators': 200, 'max_depth': 26, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:07,215] Trial 101 finished with value: 0.8582455194463859 and parameters: {'model': 'RandomForest', 'n_estimators': 188, 'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:07,803] Trial 102 finished with value: 0.8606468779045705 and parameters: {'model': 'RandomForest', 'n_estimators': 176, 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:08,501] Trial 103 finished with value: 0.8340989964741499 and parameters: {'model': 'RandomForest', 'n_estimators': 180, 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 3}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:08,944] Trial 104 finished with value: 0.8585137503062099 and parameters: {'model': 'RandomForest', 'n_estimators': 193, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:09,166] Trial 105 finished with value: 0.8560902355282229 and parameters: {'model': 'RandomForest', 'n_estimators': 98, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:09,525] Trial 106 finished with value: 0.8604353141620926 and parameters: {'model': 'RandomForest', 'n_estimators': 165, 'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:09,868] Trial 107 finished with value: 0.856975525018155 and parameters: {'model': 'RandomForest', 'n_estimators': 171, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:10,250] Trial 108 finished with value: 0.8543441611583079 and parameters: {'model': 'RandomForest', 'n_estimators': 186, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 12}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:10,751] Trial 109 finished with value: 0.7135847969912064 and parameters: {'model': 'GradientBoosting', 'n_estimators': 182, 'max_depth': 9, 'learning_rate': 0.04610125688070353}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:11,087] Trial 110 finished with value: 0.8604999847696231 and parameters: {'model': 'RandomForest', 'n_estimators': 157, 'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:11,445] Trial 111 finished with value: 0.8606603240163163 and parameters: {'model': 'RandomForest', 'n_estimators': 177, 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:11,796] Trial 112 finished with value: 0.859527036825523 and parameters: {'model': 'RandomForest', 'n_estimators': 174, 'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:11,863] Trial 113 finished with value: 0.8441414111136162 and parameters: {'model': 'RandomForest', 'n_estimators': 11, 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:12,236] Trial 114 finished with value: 0.8576647785525405 and parameters: {'model': 'RandomForest', 'n_estimators': 178, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:12,562] Trial 115 finished with value: 0.8460576589379624 and parameters: {'model': 'RandomForest', 'n_estimators': 188, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:12,913] Trial 116 finished with value: 0.856935847571344 and parameters: {'model': 'RandomForest', 'n_estimators': 165, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:13,272] Trial 117 finished with value: 0.8609022720336242 and parameters: {'model': 'RandomForest', 'n_estimators': 172, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:13,578] Trial 118 finished with value: 0.8427250755884697 and parameters: {'model': 'RandomForest', 'n_estimators': 121, 'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:13,936] Trial 119 finished with value: 0.8611253452878176 and parameters: {'model': 'RandomForest', 'n_estimators': 170, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:14,251] Trial 120 finished with value: 0.7658126835815642 and parameters: {'model': 'XGBoost', 'n_estimators': 152, 'max_depth': 19, 'learning_rate': 0.09310424837391909}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:14,593] Trial 121 finished with value: 0.8606828034186393 and parameters: {'model': 'RandomForest', 'n_estimators': 169, 'max_depth': 21, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:14,942] Trial 122 finished with value: 0.8606828034186393 and parameters: {'model': 'RandomForest', 'n_estimators': 169, 'max_depth': 22, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:15,302] Trial 123 finished with value: 0.8609513230570951 and parameters: {'model': 'RandomForest', 'n_estimators': 173, 'max_depth': 20, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:15,499] Trial 124 finished with value: 0.8563977008661963 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:15,836] Trial 125 finished with value: 0.8602070368762744 and parameters: {'model': 'RandomForest', 'n_estimators': 160, 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:16,206] Trial 126 finished with value: 0.8604090942142524 and parameters: {'model': 'RandomForest', 'n_estimators': 184, 'max_depth': 19, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:16,581] Trial 127 finished with value: 0.8555743544674513 and parameters: {'model': 'RandomForest', 'n_estimators': 191, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:16,954] Trial 128 finished with value: 0.860791337604093 and parameters: {'model': 'RandomForest', 'n_estimators': 174, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:17,140] Trial 129 finished with value: 0.8565256190644104 and parameters: {'model': 'RandomForest', 'n_estimators': 75, 'max_depth': 19, 'min_samples_split': 13, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:17,346] Trial 130 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:17,557] Trial 131 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:17,765] Trial 132 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:17,966] Trial 133 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:18,179] Trial 134 finished with value: 0.8583179770838265 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:18,390] Trial 135 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:18,637] Trial 136 finished with value: 0.736883653174038 and parameters: {'model': 'GradientBoosting', 'n_estimators': 88, 'max_depth': 16, 'learning_rate': 0.146473333365141}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:19,019] Trial 137 finished with value: 0.858064360750233 and parameters: {'model': 'RandomForest', 'n_estimators': 104, 'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:19,415] Trial 138 finished with value: 0.853783382806753 and parameters: {'model': 'RandomForest', 'n_estimators': 110, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:19,684] Trial 139 finished with value: 0.8604139879362135 and parameters: {'model': 'RandomForest', 'n_estimators': 71, 'max_depth': 13, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:20,018] Trial 140 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:20,337] Trial 141 finished with value: 0.8601440663784172 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:20,643] Trial 142 finished with value: 0.8602013107186632 and parameters: {'model': 'RandomForest', 'n_estimators': 79, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:21,026] Trial 143 finished with value: 0.8458613013409202 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 24, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:21,400] Trial 144 finished with value: 0.8586368185961052 and parameters: {'model': 'RandomForest', 'n_estimators': 101, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:21,737] Trial 145 finished with value: 0.8572816398070036 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:22,595] Trial 146 finished with value: 0.5958337561405711 and parameters: {'model': 'XGBoost', 'n_estimators': 67, 'max_depth': 20, 'learning_rate': 0.01121831404763557}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:22,802] Trial 147 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:22,994] Trial 148 finished with value: 0.859622765458148 and parameters: {'model': 'RandomForest', 'n_estimators': 76, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:23,207] Trial 149 finished with value: 0.8583610999285218 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:23,434] Trial 150 finished with value: 0.8598085228184051 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:23,632] Trial 151 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:23,992] Trial 152 finished with value: 0.8609513230570951 and parameters: {'model': 'RandomForest', 'n_estimators': 173, 'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:24,363] Trial 153 finished with value: 0.8609513230570951 and parameters: {'model': 'RandomForest', 'n_estimators': 173, 'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:24,717] Trial 154 finished with value: 0.8609513230570951 and parameters: {'model': 'RandomForest', 'n_estimators': 173, 'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:25,099] Trial 155 finished with value: 0.8506005008509228 and parameters: {'model': 'RandomForest', 'n_estimators': 164, 'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:25,327] Trial 156 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:25,520] Trial 157 finished with value: 0.8604313766637648 and parameters: {'model': 'RandomForest', 'n_estimators': 78, 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:25,886] Trial 158 finished with value: 0.8575099728237928 and parameters: {'model': 'RandomForest', 'n_estimators': 172, 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:26,260] Trial 159 finished with value: 0.8565869675842857 and parameters: {'model': 'RandomForest', 'n_estimators': 168, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:26,621] Trial 160 finished with value: 0.8610054435286688 and parameters: {'model': 'RandomForest', 'n_estimators': 178, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:27,029] Trial 161 finished with value: 0.8333032462148291 and parameters: {'model': 'RandomForest', 'n_estimators': 178, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 5}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:27,417] Trial 162 finished with value: 0.860791337604093 and parameters: {'model': 'RandomForest', 'n_estimators': 174, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:27,770] Trial 163 finished with value: 0.86098418001489 and parameters: {'model': 'RandomForest', 'n_estimators': 179, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:28,138] Trial 164 finished with value: 0.86098418001489 and parameters: {'model': 'RandomForest', 'n_estimators': 179, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:28,412] Trial 165 finished with value: 0.7167052491493039 and parameters: {'model': 'GradientBoosting', 'n_estimators': 179, 'max_depth': 13, 'learning_rate': 0.2256248276239935}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:28,778] Trial 166 finished with value: 0.8600567239827316 and parameters: {'model': 'RandomForest', 'n_estimators': 186, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:28,977] Trial 167 finished with value: 0.8591611184673507 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:29,355] Trial 168 finished with value: 0.86136616925533 and parameters: {'model': 'RandomForest', 'n_estimators': 180, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:29,728] Trial 169 finished with value: 0.8580398000801759 and parameters: {'model': 'RandomForest', 'n_estimators': 180, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:29,932] Trial 170 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:30,138] Trial 171 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:30,363] Trial 172 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:30,581] Trial 173 finished with value: 0.8591279899096327 and parameters: {'model': 'RandomForest', 'n_estimators': 99, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:30,790] Trial 174 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:30,996] Trial 175 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:31,203] Trial 176 finished with value: 0.8574118942518069 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:31,380] Trial 177 finished with value: 0.7532669597381432 and parameters: {'model': 'XGBoost', 'n_estimators': 98, 'max_depth': 10, 'learning_rate': 0.18288211309824198}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:31,596] Trial 178 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:31,800] Trial 179 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:32,032] Trial 180 finished with value: 0.8576843469759843 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:32,268] Trial 181 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:32,480] Trial 182 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:32,745] Trial 183 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:33,036] Trial 184 finished with value: 0.8600232808484368 and parameters: {'model': 'RandomForest', 'n_estimators': 75, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:33,382] Trial 185 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:33,693] Trial 186 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:33,997] Trial 187 finished with value: 0.8601440663784172 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:34,364] Trial 188 finished with value: 0.8572420291546057 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:34,710] Trial 189 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:35,022] Trial 190 finished with value: 0.8602013107186632 and parameters: {'model': 'RandomForest', 'n_estimators': 79, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:35,383] Trial 191 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:35,731] Trial 192 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:36,064] Trial 193 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:36,420] Trial 194 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:36,634] Trial 195 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:36,839] Trial 196 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:37,048] Trial 197 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:37,271] Trial 198 finished with value: 0.8564964038677525 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:37,548] Trial 199 finished with value: 0.7350768937645342 and parameters: {'model': 'GradientBoosting', 'n_estimators': 87, 'max_depth': 9, 'learning_rate': 0.14728059639562463}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:37,748] Trial 200 finished with value: 0.8591611184673507 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:37,945] Trial 201 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:38,156] Trial 202 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:38,366] Trial 203 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:38,583] Trial 204 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:38,783] Trial 205 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:38,994] Trial 206 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:39,207] Trial 207 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:39,437] Trial 208 finished with value: 0.8586368185961052 and parameters: {'model': 'RandomForest', 'n_estimators': 101, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:39,635] Trial 209 finished with value: 0.8604313766637648 and parameters: {'model': 'RandomForest', 'n_estimators': 78, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:39,834] Trial 210 finished with value: 0.8565590380900687 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:40,033] Trial 211 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:40,231] Trial 212 finished with value: 0.8591611184673507 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:40,447] Trial 213 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:40,666] Trial 214 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:40,881] Trial 215 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:41,100] Trial 216 finished with value: 0.8598085228184051 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:41,320] Trial 217 finished with value: 0.8574118942518069 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:41,527] Trial 218 finished with value: 0.8486351413586419 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:41,700] Trial 219 finished with value: 0.7846778404473672 and parameters: {'model': 'XGBoost', 'n_estimators': 72, 'max_depth': 12, 'learning_rate': 0.2650327091807861}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:41,915] Trial 220 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:42,120] Trial 221 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:42,341] Trial 222 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:42,550] Trial 223 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:42,788] Trial 224 finished with value: 0.8596392210102706 and parameters: {'model': 'RandomForest', 'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:42,975] Trial 225 finished with value: 0.8591611184673507 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:43,176] Trial 226 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:43,408] Trial 227 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:43,604] Trial 228 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:43,833] Trial 229 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:44,038] Trial 230 finished with value: 0.842278162923781 and parameters: {'model': 'RandomForest', 'n_estimators': 78, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:44,249] Trial 231 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:44,466] Trial 232 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:44,677] Trial 233 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:44,922] Trial 234 finished with value: 0.8596392210102706 and parameters: {'model': 'RandomForest', 'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:45,127] Trial 235 finished with value: 0.8601440663784172 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:45,356] Trial 236 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:45,562] Trial 237 finished with value: 0.8581018477121308 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:45,778] Trial 238 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:46,003] Trial 239 finished with value: 0.8591279899096327 and parameters: {'model': 'RandomForest', 'n_estimators': 99, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:46,215] Trial 240 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:46,456] Trial 241 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:46,834] Trial 242 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:47,195] Trial 243 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:47,509] Trial 244 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:47,847] Trial 245 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:48,173] Trial 246 finished with value: 0.859451101171892 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:48,550] Trial 247 finished with value: 0.7378448923833216 and parameters: {'model': 'GradientBoosting', 'n_estimators': 94, 'max_depth': 10, 'learning_rate': 0.21634958514437927}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:48,895] Trial 248 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:49,243] Trial 249 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:49,641] Trial 250 finished with value: 0.8553987336840903 and parameters: {'model': 'RandomForest', 'n_estimators': 103, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:50,010] Trial 251 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:50,314] Trial 252 finished with value: 0.8602013107186632 and parameters: {'model': 'RandomForest', 'n_estimators': 79, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:50,530] Trial 253 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:50,731] Trial 254 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:50,953] Trial 255 finished with value: 0.8563414079959589 and parameters: {'model': 'RandomForest', 'n_estimators': 97, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:51,180] Trial 256 finished with value: 0.7569894472357245 and parameters: {'model': 'XGBoost', 'n_estimators': 83, 'max_depth': 12, 'learning_rate': 0.08163732415202654}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:51,390] Trial 257 finished with value: 0.8600232808484368 and parameters: {'model': 'RandomForest', 'n_estimators': 75, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:51,606] Trial 258 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:51,821] Trial 259 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:52,060] Trial 260 finished with value: 0.8315885507082835 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:52,278] Trial 261 finished with value: 0.8563977008661963 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:52,503] Trial 262 finished with value: 0.8601896203923466 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:52,709] Trial 263 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:52,922] Trial 264 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:53,169] Trial 265 finished with value: 0.8591279899096327 and parameters: {'model': 'RandomForest', 'n_estimators': 99, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:53,398] Trial 266 finished with value: 0.8570771791074248 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:53,606] Trial 267 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:53,801] Trial 268 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:53,984] Trial 269 finished with value: 0.7172265936367137 and parameters: {'model': 'GradientBoosting', 'n_estimators': 87, 'max_depth': 13, 'learning_rate': 0.2965214448770894}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:54,214] Trial 270 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:54,421] Trial 271 finished with value: 0.8604313766637648 and parameters: {'model': 'RandomForest', 'n_estimators': 78, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:54,626] Trial 272 finished with value: 0.8565590380900687 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:54,860] Trial 273 finished with value: 0.8384435288840736 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:55,061] Trial 274 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:55,268] Trial 275 finished with value: 0.8600232808484368 and parameters: {'model': 'RandomForest', 'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:55,522] Trial 276 finished with value: 0.8576902858623687 and parameters: {'model': 'RandomForest', 'n_estimators': 108, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:55,665] Trial 277 finished with value: 0.8533237545315073 and parameters: {'model': 'RandomForest', 'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:55,813] Trial 278 finished with value: 0.7541307456404627 and parameters: {'model': 'XGBoost', 'n_estimators': 96, 'max_depth': 12, 'learning_rate': 0.24586647428862127}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:56,016] Trial 279 finished with value: 0.8601440663784172 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:56,255] Trial 280 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:56,481] Trial 281 finished with value: 0.8547237298069825 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 11}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:56,707] Trial 282 finished with value: 0.8586368185961052 and parameters: {'model': 'RandomForest', 'n_estimators': 101, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:56,903] Trial 283 finished with value: 0.859451101171892 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:57,123] Trial 284 finished with value: 0.8570771791074248 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:57,345] Trial 285 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:57,563] Trial 286 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:57,800] Trial 287 finished with value: 0.8596392210102706 and parameters: {'model': 'RandomForest', 'n_estimators': 97, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:58,006] Trial 288 finished with value: 0.8583610999285218 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:58,217] Trial 289 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:58,451] Trial 290 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:58,680] Trial 291 finished with value: 0.8532750551780737 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:58,891] Trial 292 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:59,106] Trial 293 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:59,351] Trial 294 finished with value: 0.7204207931109626 and parameters: {'model': 'GradientBoosting', 'n_estimators': 77, 'max_depth': 10, 'learning_rate': 0.049381488116584896}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:59,568] Trial 295 finished with value: 0.8583610999285218 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:12:59,831] Trial 296 finished with value: 0.8573218339673484 and parameters: {'model': 'RandomForest', 'n_estimators': 116, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:00,051] Trial 297 finished with value: 0.8601896203923466 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:00,266] Trial 298 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:00,654] Trial 299 finished with value: 0.8591279899096327 and parameters: {'model': 'RandomForest', 'n_estimators': 99, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:00,993] Trial 300 finished with value: 0.8560455540820215 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:03,420] Trial 301 finished with value: 0.7968144312075516 and parameters: {'model': 'XGBoost', 'n_estimators': 90, 'max_depth': 10, 'learning_rate': 0.27020362746489474}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:03,742] Trial 302 finished with value: 0.8602013107186632 and parameters: {'model': 'RandomForest', 'n_estimators': 79, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:03,959] Trial 303 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:04,171] Trial 304 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:04,417] Trial 305 finished with value: 0.858064360750233 and parameters: {'model': 'RandomForest', 'n_estimators': 104, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:04,665] Trial 306 finished with value: 0.8480002695759539 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:04,881] Trial 307 finished with value: 0.8581018477121308 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:05,107] Trial 308 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:05,300] Trial 309 finished with value: 0.8602898863728994 and parameters: {'model': 'RandomForest', 'n_estimators': 74, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:05,520] Trial 310 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:05,750] Trial 311 finished with value: 0.8596392210102706 and parameters: {'model': 'RandomForest', 'n_estimators': 97, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:06,000] Trial 312 finished with value: 0.8170311036685532 and parameters: {'model': 'RandomForest', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:06,204] Trial 313 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:06,479] Trial 314 finished with value: 0.7377879349058547 and parameters: {'model': 'GradientBoosting', 'n_estimators': 91, 'max_depth': 10, 'learning_rate': 0.11949047518581282}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:06,708] Trial 315 finished with value: 0.8583610999285218 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:06,917] Trial 316 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:07,152] Trial 317 finished with value: 0.8601896203923466 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:07,381] Trial 318 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:07,587] Trial 319 finished with value: 0.8604313766637648 and parameters: {'model': 'RandomForest', 'n_estimators': 78, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:07,821] Trial 320 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:08,045] Trial 321 finished with value: 0.856930163421024 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:08,272] Trial 322 finished with value: 0.8591611184673507 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:08,502] Trial 323 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:08,709] Trial 324 finished with value: 0.7655387343143523 and parameters: {'model': 'XGBoost', 'n_estimators': 101, 'max_depth': 9, 'learning_rate': 0.13797015167090385}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:08,923] Trial 325 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:09,155] Trial 326 finished with value: 0.8563414079959589 and parameters: {'model': 'RandomForest', 'n_estimators': 97, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:09,394] Trial 327 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:09,618] Trial 328 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:09,831] Trial 329 finished with value: 0.8562253805586083 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:10,031] Trial 330 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:10,271] Trial 331 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:10,497] Trial 332 finished with value: 0.8531323661382957 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 11}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:10,626] Trial 333 finished with value: 0.8465785174330223 and parameters: {'model': 'RandomForest', 'n_estimators': 38, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:10,886] Trial 334 finished with value: 0.8601896203923466 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:11,112] Trial 335 finished with value: 0.8498135940063486 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:11,324] Trial 336 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:11,423] Trial 337 finished with value: 0.8461841019929365 and parameters: {'model': 'RandomForest', 'n_estimators': 17, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:11,662] Trial 338 finished with value: 0.7297440018405641 and parameters: {'model': 'GradientBoosting', 'n_estimators': 76, 'max_depth': 12, 'learning_rate': 0.17278598190587527}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:11,894] Trial 339 finished with value: 0.8570771791074248 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:12,129] Trial 340 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:12,387] Trial 341 finished with value: 0.8591279899096327 and parameters: {'model': 'RandomForest', 'n_estimators': 99, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:12,604] Trial 342 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:12,840] Trial 343 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:13,085] Trial 344 finished with value: 0.8531115461475687 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:13,293] Trial 345 finished with value: 0.7457893722089274 and parameters: {'model': 'XGBoost', 'n_estimators': 91, 'max_depth': 11, 'learning_rate': 0.03119268167542892}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:13,514] Trial 346 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:13,737] Trial 347 finished with value: 0.8570073393680773 and parameters: {'model': 'RandomForest', 'n_estimators': 79, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:14,115] Trial 348 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:14,469] Trial 349 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:14,852] Trial 350 finished with value: 0.8601896203923466 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:15,178] Trial 351 finished with value: 0.8563977008661963 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:15,530] Trial 352 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:15,884] Trial 353 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:16,203] Trial 354 finished with value: 0.8564974681641948 and parameters: {'model': 'RandomForest', 'n_estimators': 77, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:16,569] Trial 355 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:16,975] Trial 356 finished with value: 0.8289202123099766 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:17,379] Trial 357 finished with value: 0.8591279899096327 and parameters: {'model': 'RandomForest', 'n_estimators': 99, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:17,749] Trial 358 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:17,989] Trial 359 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:18,239] Trial 360 finished with value: 0.7331802996533437 and parameters: {'model': 'GradientBoosting', 'n_estimators': 72, 'max_depth': 13, 'learning_rate': 0.20236847923501047}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:18,459] Trial 361 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:18,668] Trial 362 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:18,914] Trial 363 finished with value: 0.8390088834204407 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:19,223] Trial 364 finished with value: 0.8545266234483799 and parameters: {'model': 'RandomForest', 'n_estimators': 127, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:19,468] Trial 365 finished with value: 0.8598085228184051 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:19,716] Trial 366 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:19,943] Trial 367 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:20,162] Trial 368 finished with value: 0.8570919818454389 and parameters: {'model': 'RandomForest', 'n_estimators': 78, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:20,394] Trial 369 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:20,645] Trial 370 finished with value: 0.6897125419708985 and parameters: {'model': 'XGBoost', 'n_estimators': 93, 'max_depth': 12, 'learning_rate': 0.012435785898585572}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:21,073] Trial 371 finished with value: 0.857581370364346 and parameters: {'model': 'RandomForest', 'n_estimators': 105, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:21,428] Trial 372 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:21,758] Trial 373 finished with value: 0.8591611184673507 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:22,184] Trial 374 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:23,281] Trial 375 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:23,688] Trial 376 finished with value: 0.855696186707983 and parameters: {'model': 'RandomForest', 'n_estimators': 100, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:24,066] Trial 377 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:24,476] Trial 378 finished with value: 0.8598085228184051 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:24,859] Trial 379 finished with value: 0.8264892284599363 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:25,112] Trial 380 finished with value: 0.8572816398070036 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:25,340] Trial 381 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:25,590] Trial 382 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:25,869] Trial 383 finished with value: 0.7304069156740152 and parameters: {'model': 'GradientBoosting', 'n_estimators': 90, 'max_depth': 10, 'learning_rate': 0.08006321140794231}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:26,068] Trial 384 finished with value: 0.8598792715295376 and parameters: {'model': 'RandomForest', 'n_estimators': 77, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:26,326] Trial 385 finished with value: 0.8598085228184051 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:26,568] Trial 386 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:26,795] Trial 387 finished with value: 0.8601440663784172 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:26,976] Trial 388 finished with value: 0.8565891159970627 and parameters: {'model': 'RandomForest', 'n_estimators': 63, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:27,211] Trial 389 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:27,449] Trial 390 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:27,674] Trial 391 finished with value: 0.8562253805586083 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:27,991] Trial 392 finished with value: 0.8601896203923466 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:31,007] Trial 393 finished with value: 0.7569443026496339 and parameters: {'model': 'XGBoost', 'n_estimators': 74, 'max_depth': 12, 'learning_rate': 0.10680700800469455}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:31,228] Trial 394 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:31,467] Trial 395 finished with value: 0.8586368185961052 and parameters: {'model': 'RandomForest', 'n_estimators': 101, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:31,713] Trial 396 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:31,963] Trial 397 finished with value: 0.8583179770838265 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:32,205] Trial 398 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:32,419] Trial 399 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:32,637] Trial 400 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:32,862] Trial 401 finished with value: 0.8562253805586083 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:33,109] Trial 402 finished with value: 0.859343131233089 and parameters: {'model': 'RandomForest', 'n_estimators': 98, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:33,337] Trial 403 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:33,550] Trial 404 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:33,783] Trial 405 finished with value: 0.8601440663784172 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:34,009] Trial 406 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:34,237] Trial 407 finished with value: 0.7191580503185306 and parameters: {'model': 'GradientBoosting', 'n_estimators': 86, 'max_depth': 12, 'learning_rate': 0.23707592756506768}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:34,459] Trial 408 finished with value: 0.8466965589355896 and parameters: {'model': 'RandomForest', 'n_estimators': 76, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:34,696] Trial 409 finished with value: 0.8596392210102706 and parameters: {'model': 'RandomForest', 'n_estimators': 97, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:34,918] Trial 410 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:35,143] Trial 411 finished with value: 0.8574118942518069 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:35,367] Trial 412 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:35,526] Trial 413 finished with value: 0.7777385033973825 and parameters: {'model': 'XGBoost', 'n_estimators': 94, 'max_depth': 13, 'learning_rate': 0.25566908280084166}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:35,747] Trial 414 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:35,977] Trial 415 finished with value: 0.8560446133483637 and parameters: {'model': 'RandomForest', 'n_estimators': 69, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:36,300] Trial 416 finished with value: 0.8523215586701278 and parameters: {'model': 'RandomForest', 'n_estimators': 138, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 12}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:36,576] Trial 417 finished with value: 0.824283064047093 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:36,815] Trial 418 finished with value: 0.8588045800512351 and parameters: {'model': 'RandomForest', 'n_estimators': 102, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:37,031] Trial 419 finished with value: 0.8602013107186632 and parameters: {'model': 'RandomForest', 'n_estimators': 79, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:37,254] Trial 420 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:37,481] Trial 421 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:37,707] Trial 422 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:37,948] Trial 423 finished with value: 0.8564964038677525 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:38,174] Trial 424 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:38,384] Trial 425 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:38,618] Trial 426 finished with value: 0.856930163421024 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:38,888] Trial 427 finished with value: 0.7360706193196409 and parameters: {'model': 'GradientBoosting', 'n_estimators': 90, 'max_depth': 11, 'learning_rate': 0.16737780701422655}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:39,110] Trial 428 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:39,357] Trial 429 finished with value: 0.859343131233089 and parameters: {'model': 'RandomForest', 'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:39,557] Trial 430 finished with value: 0.8600232808484368 and parameters: {'model': 'RandomForest', 'n_estimators': 75, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:39,787] Trial 431 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:40,007] Trial 432 finished with value: 0.8560455540820215 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:40,246] Trial 433 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:40,472] Trial 434 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:40,678] Trial 435 finished with value: 0.8604313766637648 and parameters: {'model': 'RandomForest', 'n_estimators': 78, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:40,875] Trial 436 finished with value: 0.7482386752483006 and parameters: {'model': 'XGBoost', 'n_estimators': 90, 'max_depth': 10, 'learning_rate': 0.037710876395924506}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:41,196] Trial 437 finished with value: 0.8560643689067589 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:41,567] Trial 438 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:41,930] Trial 439 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:42,390] Trial 440 finished with value: 0.8416946676268393 and parameters: {'model': 'RandomForest', 'n_estimators': 98, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:42,746] Trial 441 finished with value: 0.8601440663784172 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 13, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:43,200] Trial 442 finished with value: 0.855607546833541 and parameters: {'model': 'RandomForest', 'n_estimators': 112, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:43,660] Trial 443 finished with value: 0.8576843469759843 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:44,058] Trial 444 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:44,832] Trial 445 finished with value: 0.8602013107186632 and parameters: {'model': 'RandomForest', 'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:45,258] Trial 446 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:45,502] Trial 447 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:45,755] Trial 448 finished with value: 0.8584019535736576 and parameters: {'model': 'RandomForest', 'n_estimators': 103, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:45,961] Trial 449 finished with value: 0.7360998654003895 and parameters: {'model': 'GradientBoosting', 'n_estimators': 83, 'max_depth': 10, 'learning_rate': 0.2872754220559497}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:46,320] Trial 450 finished with value: 0.8583179770838265 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:46,678] Trial 451 finished with value: 0.8598085228184051 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:47,076] Trial 452 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:47,527] Trial 453 finished with value: 0.8589982331373357 and parameters: {'model': 'RandomForest', 'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:48,026] Trial 454 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:48,355] Trial 455 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:48,597] Trial 456 finished with value: 0.8570771791074248 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:48,866] Trial 457 finished with value: 0.8579439037079439 and parameters: {'model': 'RandomForest', 'n_estimators': 107, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:49,096] Trial 458 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:49,276] Trial 459 finished with value: 0.7793844435443245 and parameters: {'model': 'XGBoost', 'n_estimators': 98, 'max_depth': 9, 'learning_rate': 0.193518557633176}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:49,517] Trial 460 finished with value: 0.8604313766637648 and parameters: {'model': 'RandomForest', 'n_estimators': 78, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:49,762] Trial 461 finished with value: 0.8567689274365207 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:50,001] Trial 462 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:50,365] Trial 463 finished with value: 0.8605032893806936 and parameters: {'model': 'RandomForest', 'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:50,911] Trial 464 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:51,377] Trial 465 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:51,927] Trial 466 finished with value: 0.859451101171892 and parameters: {'model': 'RandomForest', 'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:52,687] Trial 467 finished with value: 0.8570162215862787 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:53,296] Trial 468 finished with value: 0.8588063035165671 and parameters: {'model': 'RandomForest', 'n_estimators': 100, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:53,785] Trial 469 finished with value: 0.8594898029400723 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:54,385] Trial 470 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:54,816] Trial 471 finished with value: 0.8570771791074248 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:55,739] Trial 472 finished with value: 0.8150451132651731 and parameters: {'model': 'RandomForest', 'n_estimators': 58, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:56,115] Trial 473 finished with value: 0.7362422525693817 and parameters: {'model': 'GradientBoosting', 'n_estimators': 82, 'max_depth': 14, 'learning_rate': 0.21934317221254596}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:56,575] Trial 474 finished with value: 0.8615859999224962 and parameters: {'model': 'RandomForest', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:57,050] Trial 475 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:57,643] Trial 476 finished with value: 0.8564964038677525 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:58,311] Trial 477 finished with value: 0.8599380215198746 and parameters: {'model': 'RandomForest', 'n_estimators': 85, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:58,669] Trial 478 finished with value: 0.8602013107186632 and parameters: {'model': 'RandomForest', 'n_estimators': 79, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:59,096] Trial 479 finished with value: 0.859622765458148 and parameters: {'model': 'RandomForest', 'n_estimators': 76, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:59,291] Trial 480 finished with value: 0.7494428096660113 and parameters: {'model': 'XGBoost', 'n_estimators': 89, 'max_depth': 9, 'learning_rate': 0.061265386025220345}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:59,414] Trial 481 finished with value: 0.8409318544061695 and parameters: {'model': 'RandomForest', 'n_estimators': 23, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:59,660] Trial 482 finished with value: 0.8602762375038372 and parameters: {'model': 'RandomForest', 'n_estimators': 93, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:13:59,896] Trial 483 finished with value: 0.8601440663784172 and parameters: {'model': 'RandomForest', 'n_estimators': 83, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:00,127] Trial 484 finished with value: 0.8620271351624469 and parameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:00,413] Trial 485 finished with value: 0.855696186707983 and parameters: {'model': 'RandomForest', 'n_estimators': 100, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:00,646] Trial 486 finished with value: 0.8609680443399499 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:00,896] Trial 487 finished with value: 0.8605322097051558 and parameters: {'model': 'RandomForest', 'n_estimators': 92, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:01,123] Trial 488 finished with value: 0.8596321545828352 and parameters: {'model': 'RandomForest', 'n_estimators': 81, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:01,470] Trial 489 finished with value: 0.8524914684649755 and parameters: {'model': 'RandomForest', 'n_estimators': 95, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 11}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:01,900] Trial 490 finished with value: 0.8618051921144719 and parameters: {'model': 'RandomForest', 'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:02,179] Trial 491 finished with value: 0.8560643689067589 and parameters: {'model': 'RandomForest', 'n_estimators': 84, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:02,427] Trial 492 finished with value: 0.8607842633117129 and parameters: {'model': 'RandomForest', 'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:02,644] Trial 493 finished with value: 0.8598792715295376 and parameters: {'model': 'RandomForest', 'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:02,875] Trial 494 finished with value: 0.856957036439807 and parameters: {'model': 'RandomForest', 'n_estimators': 86, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 12}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:03,169] Trial 495 finished with value: 0.7322055074538143 and parameters: {'model': 'GradientBoosting', 'n_estimators': 72, 'max_depth': 11, 'learning_rate': 0.20794425019327534}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:03,371] Trial 496 finished with value: 0.8545365772738099 and parameters: {'model': 'RandomForest', 'n_estimators': 50, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:03,619] Trial 497 finished with value: 0.8564964038677525 and parameters: {'model': 'RandomForest', 'n_estimators': 96, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:03,834] Trial 498 finished with value: 0.8591611184673507 and parameters: {'model': 'RandomForest', 'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n","[I 2024-06-15 13:14:04,088] Trial 499 finished with value: 0.8609984833530744 and parameters: {'model': 'RandomForest', 'n_estimators': 90, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 41 with value: 0.8620271351624469.\n"]},{"output_type":"stream","name":"stdout","text":["Best model: RandomForest\n","Best hyperparameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 14}\n","Best R2 score: 0.8620271351624469\n","Final R2 score: 0.8620271351624469\n"]}]},{"cell_type":"markdown","source":["## 2C: Explainability\n","\n","In this part, we will be employing explainability analysis on the best model using *Shapley Values*. We will be showing a plot of the features with the most impact on the G3 scoes.\n","\n","It appears that our best model is the RandomForestRegressor, with the parameters indicated above (Best hyperparameters: {'model': 'RandomForest', 'n_estimators': 88, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 14}), besting XGBoost and GradientBoosting algorithms.\n"],"metadata":{"id":"enqSxmmwhSoS"}},{"cell_type":"code","source":["import shap\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# Assuming the best pipeline includes a RandomForestRegressor\n","best_model = RandomForestRegressor(n_estimators=88, max_depth=15, min_samples_split=13, min_samples_leaf=14, random_state=42)\n","best_model.fit(X_train, y_train)\n","\n","# Create a SHAP explainer\n","explainer = shap.TreeExplainer(best_model)\n","shap_values = explainer.shap_values(X_test)\n","\n","# Plot summary plot\n","shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":957},"id":"IqdzThnRkv9P","executionInfo":{"status":"ok","timestamp":1718457296635,"user_tz":-480,"elapsed":1697,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"9c9c798b-5f26-45bf-bb98-8d549ccbbf8e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x950 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["print(shap_values)\n","# Convert SHAP values to a DataFrame\n","shap_df = pd.DataFrame(shap_values, columns=X_test.columns)\n","\n","# Save the DataFrame to a CSV file\n","shap_df.to_csv('shap_values.csv', index=False)\n","\n","print(\"SHAP values have been saved to 'shap_values.csv'.\")\n","\n","from google.colab import files\n","\n","# Download the CSV file\n","files.download('shap_values.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"tpzIrFef55jk","executionInfo":{"status":"ok","timestamp":1718457693483,"user_tz":-480,"elapsed":396,"user":{"displayName":"Juan Carlos Roldan","userId":"12003296752203981496"}},"outputId":"c833f857-2fd5-4c18-c662-7700814aa913"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.00000000e+00 -1.71071805e-03  6.54638206e-03 ...  8.40681274e-01\n","  -2.45825411e-02 -3.04760782e+00]\n"," [ 0.00000000e+00  5.28700949e-05 -1.07723242e-03 ...  2.82448445e-01\n","   2.73887890e-02  1.26243390e+00]\n"," [ 0.00000000e+00  5.92273038e-04 -6.22834138e-03 ...  1.06126233e+00\n","  -7.25933583e-02 -6.35646450e+00]\n"," ...\n"," [ 0.00000000e+00 -1.71071805e-03  1.81775080e-02 ...  8.94295546e-01\n","   1.70227481e-02 -2.16517269e+00]\n"," [ 0.00000000e+00  1.73839708e-04 -1.01474140e-03 ...  2.78172243e-01\n","   7.76599243e-03  3.59107915e+00]\n"," [ 0.00000000e+00  5.92273038e-04  3.92217116e-03 ...  1.06142294e+00\n","  -7.58130583e-02 -6.37061050e+00]]\n","SHAP values have been saved to 'shap_values.csv'.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_d4ccd0a3-46d5-4c5b-8019-6229fcaf98e2\", \"shap_values.csv\", 41175)"]},"metadata":{}}]},{"cell_type":"markdown","source":["The top 10 features based on the mean absolute SHAP values are:\n","\n","1. G2: 3.601914\n","2. absences: 0.689220\n","3. G1: 0.039508\n","4. Fjob: 0.009821\n","5. age: 0.009346\n","6. romantic: 0.007206\n","7. Medu: 0.006698\n","8. health: 0.006133\n","9. activities: 0.004932\n","10. reason: 0.004287\n","\n","It appears that the second-peirod grade has the highest impact on the final grade prediction. So does the first-period grade (although to a much less extent). It does support the belief that past performance supports future performance. It also shows that the number of absences does generally affect a student's performance, as they will be getting less guided material.\n","\n","Other factors such as student's father's job, their age, whether the student is engaged in a romantic relationship, or their mother's education level only marginally affects their final grade. Every other factor has quite negligible impact."],"metadata":{"id":"BgpHjI69FEs0"}}]}